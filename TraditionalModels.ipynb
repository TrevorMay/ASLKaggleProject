{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eb6baca",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "I know most in the competition are using the deep learning approach which does make sense given the size of the data and type of challenge. However I was curious what could be achieved with traditional classifier machine learning models like XGBoost, RandomForest, etc. on the aggregated dataset we made earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a09bbb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import dummy, metrics, model_selection, preprocessing\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4567009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the 'EDA & Baseline Model.ipynb for how we constructed this csv'\n",
    "train_df = pd.read_csv(r\"C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\extended_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "188425a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path                       object\n",
       "participant_id              int64\n",
       "sequence_id                 int64\n",
       "sign                       object\n",
       "start_frame                 int64\n",
       "end_frame                   int64\n",
       "total_frames                int64\n",
       "face_count                  int64\n",
       "face_nan_count              int64\n",
       "pose_count                  int64\n",
       "pose_nan_count              int64\n",
       "left_hand_count             int64\n",
       "left_hand_nan_count         int64\n",
       "right_hand_count            int64\n",
       "right_hand_nan_count        int64\n",
       "x_min                     float64\n",
       "x_max                     float64\n",
       "y_min                     float64\n",
       "y_max                     float64\n",
       "z_min                     float64\n",
       "z_max                     float64\n",
       "face_appears_pct          float64\n",
       "face_nan_pct              float64\n",
       "left_hand_appears_pct     float64\n",
       "left_hand_nan_pct         float64\n",
       "pose_appears_pct          float64\n",
       "pose_nan_pct              float64\n",
       "right_hand_appears_pct    float64\n",
       "right_hand_nan_pct        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb375b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    # for object columns figure out what to do\n",
    "    df = df.drop(['path', 'participant_id', 'sequence_id'], axis=1)\n",
    "    df[\"sign\"] = df[\"sign\"].astype(\"category\")\n",
    "    le = LabelEncoder()\n",
    "    df['sign'] = le.fit_transform(df['sign'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_train_test_X_y(df, size=.9):\n",
    "    \"\"\"We don't want to impute or standardize on the whole dataset\n",
    "    else we are 'leaking' data\"\"\"\n",
    "    y = df.sign\n",
    "    X = df.drop(columns='sign')\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "       model_selection.train_test_split(\n",
    "       X, y, test_size=size, random_state=42,\n",
    "       stratify=y)\n",
    "    cols = X.columns\n",
    "    \n",
    "    cols = X_train.columns\n",
    "    std = preprocessing.StandardScaler()\n",
    "    X_train.loc[:, cols] = std.fit_transform(X_train)\n",
    "    X_test.loc[:,cols] = std.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "train_df = clean_df(train_df)\n",
    "X_train, X_test, y_train, y_test = get_train_test_X_y(train_df)\n",
    "\n",
    "tX = pd.concat([X_train, X_test])\n",
    "ty = pd.concat([y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69f22fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004339644831236034"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline model\n",
    "dc = dummy.DummyClassifier(random_state=42)\n",
    "dc.fit(X_train, y_train)\n",
    "dc.score(X_test, y_test)\n",
    "# oof not so good\n",
    "# but lots of room for improvement!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f3b711b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60     41\n",
       "148    41\n",
       "136    41\n",
       "135    41\n",
       "194    41\n",
       "       ..\n",
       "21     31\n",
       "56     31\n",
       "231    31\n",
       "170    31\n",
       "249    30\n",
       "Name: sign, Length: 250, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99863d9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier            Accuracy: 0.019  STD: 0.00\n",
      "DecisionTreeClassifier   Accuracy: 0.012  STD: 0.00\n",
      "KNeighborsClassifier     Accuracy: 0.014  STD: 0.00\n",
      "GaussianNB               Accuracy: 0.005  STD: 0.00\n",
      "SGDClassifier            Accuracy: 0.005  STD: 0.00\n",
      "RandomForestClassifier   Accuracy: 0.019  STD: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Try different families of models to see if one is particularly adept to this problem\n",
    "# Warning: This cell takes awhile to run\n",
    "out = []\n",
    "for model in [xgb.XGBClassifier, DecisionTreeClassifier,\n",
    "              KNeighborsClassifier, GaussianNB, SGDClassifier,\n",
    "              RandomForestClassifier]:\n",
    "    cls = model()\n",
    "    kfold = model_selection.KFold(n_splits=3)\n",
    "    res = model_selection.cross_val_score(cls, tX, ty,\n",
    "                scoring='accuracy', cv=kfold)\n",
    "    out.append(f'{cls.__class__.__name__:23}  Accuracy: {res.mean():.3f}  STD: {res.std():.2f}')\n",
    "for t in out:\n",
    "    print(t)\n",
    "# yikes it appears this is just not the approach for this competition.\n",
    "# still we will go a bit further with the best model here (RandomForest) to see what we can get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ebac412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARAMS {'random_state': 42, 'n_estimators': 1000, 'min_samples_split': 3, 'max_features': 3, 'max_depth': 10}\n",
      "ORIG 0.013689286134305539 NEW 0.014512524991179583\n"
     ]
    }
   ],
   "source": [
    "# This cell will also take awhile to run\n",
    "\n",
    "pg = {'random_state': [42],\n",
    "      'min_samples_split': [3, 10, 30], \n",
    "      'n_estimators' : [100, 300, 1000],\n",
    "      'max_depth': [None, 2, 5, 10],\n",
    "      'max_features': [3, 5, 10, 20]\n",
    "     }\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "gs = model_selection.RandomizedSearchCV(clf, param_distributions=pg, scoring='accuracy',\n",
    "                                  n_jobs=-1, \n",
    "                                  cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(\"PARAMS\", gs.best_params_)\n",
    "print(\"ORIG\", clf.score(X_test, y_test), \"NEW\", gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08228415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014888862754322003"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the result from a grid search run that took much longer and still the performance is abysmal\n",
    "clf = RandomForestClassifier(n_jobs=-1,max_depth=None, max_features=20, min_samples_split=30, n_estimators=1000, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a57357",
   "metadata": {},
   "source": [
    "It looks like there is just too much information loss in this approach and the models can't distinguish between the signs. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
