{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5460ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning and Data Science Imports\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "# for running on CoLab or within Kaggle\n",
    "# from kaggle_datasets import KaggleDatasets\n",
    "\n",
    "# Mostly Builtins\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from zipfile import ZipFile\n",
    "from glob import glob\n",
    "import Levenshtein\n",
    "import warnings\n",
    "import requests\n",
    "import hashlib\n",
    "import imageio\n",
    "import IPython\n",
    "import sklearn\n",
    "import urllib\n",
    "import zipfile\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import string\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import gzip\n",
    "import ast\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "\n",
    "# Visualization Imports (overkill)\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.patches as patches\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm; tqdm.pandas();\n",
    "import plotly.express as px\n",
    "import tifffile as tif\n",
    "import seaborn as sns\n",
    "from PIL import Image, ImageEnhance; Image.MAX_IMAGE_PIXELS = 5_000_000_000;\n",
    "import matplotlib; print(f\"\\t\\t– MATPLOTLIB VERSION: {matplotlib.__version__}\");\n",
    "from matplotlib import animation, rc; rc('animation', html='jshtml')\n",
    "import plotly\n",
    "import PIL\n",
    "\n",
    "import plotly.io as pio\n",
    "print(pio.renderers)\n",
    "\n",
    "def seed_it_all(seed=7):\n",
    "    \"\"\" Attempt to be Reproducible \"\"\"\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "seed_it_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b489bf",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e2f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_l_o_l(nested_list):\n",
    "    \"\"\"Flatten a list of lists into a single list.\n",
    "\n",
    "    Args:\n",
    "        nested_list (list): \n",
    "            – A list of lists (or iterables) to be flattened.\n",
    "\n",
    "    Returns:\n",
    "        list: A flattened list containing all items from the input list of lists.\n",
    "    \"\"\"\n",
    "    return [item for sublist in nested_list for item in sublist]\n",
    "\n",
    "\n",
    "def print_ln(symbol=\"-\", line_len=110, newline_before=False, newline_after=False):\n",
    "    \"\"\"Print a horizontal line of a specified length and symbol.\n",
    "\n",
    "    Args:\n",
    "        symbol (str, optional): \n",
    "            – The symbol to use for the horizontal line\n",
    "        line_len (int, optional): \n",
    "            – The length of the horizontal line in characters\n",
    "        newline_before (bool, optional): \n",
    "            – Whether to print a newline character before the line\n",
    "        newline_after (bool, optional): \n",
    "            – Whether to print a newline character after the line\n",
    "    \"\"\"\n",
    "    if newline_before: print();\n",
    "    print(symbol * line_len)\n",
    "    if newline_after: print();\n",
    "        \n",
    "        \n",
    "def read_json_file(file_path):\n",
    "    \"\"\"Read a JSON file and parse it into a Python object.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the JSON file to read.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary object representing the JSON data.\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If the specified file path does not exist.\n",
    "        ValueError: If the specified file path does not contain valid JSON data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open the file and load the JSON data into a Python object\n",
    "        with open(file_path, 'r') as file:\n",
    "            json_data = json.load(file)\n",
    "        return json_data\n",
    "    except FileNotFoundError:\n",
    "        # Raise an error if the file path does not exist\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    except ValueError:\n",
    "        # Raise an error if the file does not contain valid JSON data\n",
    "        raise ValueError(f\"Invalid JSON data in file: {file_path}\")\n",
    "        \n",
    "def get_sign_df(pq_path, invert_y=True):\n",
    "    sign_df = pd.read_parquet(pq_path)\n",
    "    \n",
    "    # y value is inverted (Thanks @danielpeshkov)\n",
    "    if invert_y: sign_df[\"y\"] *= -1 \n",
    "        \n",
    "    return sign_df\n",
    "\n",
    "\n",
    "ROWS_PER_FRAME = 543  # number of landmarks per frame\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8930d7b",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84e0341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the root data directory\n",
    "DATA_DIR         = str(os.getcwd()) + r\"\\asl-signs\"\n",
    "EXTEND_TRAIN_DIR = \"/kaggle/input/gislr-extended-train-dataframe\" \n",
    "\n",
    "LOAD_EXTENDED = True\n",
    "if LOAD_EXTENDED and os.path.isfile(os.path.join(EXTEND_TRAIN_DIR, \"extended_train.csv\")):\n",
    "    train_df = pd.read_csv(os.path.join(EXTEND_TRAIN_DIR, \"extended_train.csv\"))\n",
    "else:\n",
    "    train_df = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"))\n",
    "    train_df[\"path\"] = DATA_DIR+\"/\"+train_df[\"path\"]\n",
    "display(train_df)\n",
    "\n",
    "print(\"\\n\\n... LOAD SIGN TO PREDICTION INDEX MAP FROM JSON FILE ...\\n\")\n",
    "s2p_map = {k.lower():v for k,v in read_json_file(os.path.join(DATA_DIR, \"sign_to_prediction_index_map.json\")).items()}\n",
    "p2s_map = {v:k for k,v in read_json_file(os.path.join(DATA_DIR, \"sign_to_prediction_index_map.json\")).items()}\n",
    "encoder = lambda x: s2p_map.get(x.lower())\n",
    "decoder = lambda x: p2s_map.get(x)\n",
    "print(s2p_map)\n",
    "\n",
    "DEMO_ROW = 283\n",
    "print(f\"\\n\\n... DEMO SIGN/EVENT DATAFRAME FOR ROW {DEMO_ROW} - SIGN={train_df.iloc[DEMO_ROW]['sign']} ...\\n\")\n",
    "demo_sign_df = get_sign_df(train_df.iloc[DEMO_ROW][\"path\"])\n",
    "display(demo_sign_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e6816e",
   "metadata": {},
   "source": [
    "### Sample Training Data\n",
    "#### There is a lot of data here (some ~50gb) so we're going to start with doing EDA on just some of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66531538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# During interactive --> 0.001 (0.1%)\n",
    "# Save and run-all   --> 1.000 (100%)\n",
    "\n",
    "PCT_TO_EXAMINE = 0.001\n",
    "if PCT_TO_EXAMINE < 1.0:\n",
    "    subsample_train_df = train_df.sample(frac=PCT_TO_EXAMINE, random_state=42).reset_index(drop=True)\n",
    "else:\n",
    "    subsample_train_df = train_df.copy()\n",
    "\n",
    "# Remove extra columns to show what we're doing\n",
    "subsample_train_df=subsample_train_df[[\"path\", \"participant_id\", \"sequence_id\", \"sign\"]]\n",
    "display(subsample_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57829223",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2804dfae",
   "metadata": {},
   "source": [
    "##### Data Dictionary (columns and their meanings)\n",
    "Path - filepath to the landmark file (parquet)\n",
    "participant_id - who the isolated sign event parquet files are for\n",
    "sequence_id - one sequence is a single isolated sign that we have to classify (one parquet file for each, 94,477)\n",
    "sign - the label for each event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a55567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we're looking at the participant_id column\n",
    "display(train_df[\"participant_id\"].astype(str).describe().to_frame().T)\n",
    "\n",
    "print('--------------------------------------------')\n",
    "\n",
    "participant_count_map = train_df[\"participant_id\"].value_counts().to_dict()\n",
    "print(\"1. Number of Unique Participants: \", len(participant_count_map))\n",
    "print(\"2. Average Number of Rows Per Participant: \", np.array(list(participant_count_map.values())).mean())\n",
    "print(\"3. Standard Deviation in Counts Per Participant: \", np.array(list(participant_count_map.values())).std())\n",
    "print(\"4. Minimum Number of Examples For One Participant: \", np.array(list(participant_count_map.values())).min())\n",
    "print(\"5. Maximum Number of Examples For One Participant: \", np.array(list(participant_count_map.values())).max())\n",
    "\n",
    "# set participant_id to be a string\n",
    "train_df[\"participant_id\"] = train_df[\"participant_id\"].astype(str)\n",
    "subsample_train_df[\"participant_id\"] = subsample_train_df[\"participant_id\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc03050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are looking at the 'sign' column\n",
    "display(train_df[\"sign\"].describe().to_frame().T)\n",
    "\n",
    "print('-----------------------------------------------')\n",
    "\n",
    "sign_count_map = train_df[\"sign\"].value_counts().to_dict()\n",
    "print(\"1. Number Of Unique Signs: \", len(sign_count_map))\n",
    "print(\"2. Average Number of Rows Per Sign: \", np.array(list(sign_count_map.values())).mean())\n",
    "print(\"3. Standard Deviation in Counts Per Sign: \", np.array(list(sign_count_map.values())).std())\n",
    "print(\"4. Minimum Number of Examples For One Sign: \", np.array(list(sign_count_map.values())).min())\n",
    "print(\"5. Maximum Number of Examples For One Sign: \", np.array(list(sign_count_map.values())).max())\n",
    "\n",
    "# Looks like the data is pretty balanced\n",
    "# i.e. one sign is not overly represented way more than the others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f4ce9c",
   "metadata": {},
   "source": [
    "#### Now let's look at what data from the sequence parquet files might be important to include in our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ef99b8",
   "metadata": {},
   "source": [
    "For each sequence there is:\n",
    "1. start_frame\n",
    "2. end_frame\n",
    "3. total_frames\n",
    "4. face_count\n",
    "5. pose_count\n",
    "6. left_hand_count\n",
    "7. right_hand_count\n",
    "8. x_min\n",
    "9. x_max\n",
    "10. y_min\n",
    "11. y_max\n",
    "12. z_min\n",
    "13. z_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb44b249",
   "metadata": {},
   "source": [
    "### Data / Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270081d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq_meta(row, invert_y=True, do_counts=False):\n",
    "    \"\"\"Calculates and adds metadata to the given row of sign language event data.\n",
    "    \n",
    "    Args:\n",
    "        row (pandas.core.series.Series): A row of sign language event data containing columns:\n",
    "            path: The file path to the Parquet file containing the landmark data for the event.\n",
    "        invert_y (bool, optional): Whether to invert the y-coordinate of each landmark. Defaults to True.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.core.series.Series: The input row with added metadata columns:\n",
    "            start_frame: The frame number of the first frame in the event.\n",
    "            end_frame: The frame number of the last frame in the event.\n",
    "            total_frames: The number of frames in the event.\n",
    "            face_count: The number of landmarks in the 'face' type. [optional]\n",
    "            pose_count: The number of landmarks in the 'pose' type. [optional]\n",
    "            left_hand_count: The number of landmarks in the 'left_hand' type. [optional]\n",
    "            right_hand_count: The number of landmarks in the 'right_hand' type. [optional]\n",
    "            x_min: The minimum x-coordinate value of any landmark in the event.\n",
    "            x_max: The maximum x-coordinate value of any landmark in the event.\n",
    "            y_min: The minimum y-coordinate value of any landmark in the event.\n",
    "            y_max: The maximum y-coordinate value of any landmark in the event.\n",
    "            z_min: The minimum z-coordinate value of any landmark in the event.\n",
    "            z_max: The maximum z-coordinate value of any landmark in the event.\n",
    "    \"\"\"\n",
    "    # Extract the sign language event data from the Parquet file at the given path\n",
    "    df = get_sign_df(row['path'], invert_y=invert_y)\n",
    "    \n",
    "    # Count the number of landmarks in each type\n",
    "    type_counts = df['type'].value_counts(dropna=False).to_dict()\n",
    "    nan_counts  = df.groupby(\"type\")[\"x\"].apply(lambda x: x.isna().sum())\n",
    "    \n",
    "    # Calculate metadata for the event and add it to the input row\n",
    "    row['start_frame'] = df['frame'].min()\n",
    "    row['end_frame'] = df['frame'].max()\n",
    "    row['total_frames'] = df['frame'].nunique()\n",
    "    \n",
    "    if do_counts:\n",
    "        for _type in [\"face\", \"pose\", \"left_hand\", \"right_hand\"]:\n",
    "            row[f'{_type}_count'] = type_counts[_type]\n",
    "            row[f'{_type}_nan_count'] = nan_counts[_type]\n",
    "        \n",
    "    for coord in ['x', 'y', 'z']:\n",
    "        row[f'{coord}_min'] = df[coord].min()\n",
    "        row[f'{coord}_max'] = df[coord].max()\n",
    "    \n",
    "    return row\n",
    "\n",
    "type_kp_map = dict(face=468, left_hand=21, pose=33, right_hand=21)\n",
    "col_order = [\n",
    "    'path', 'participant_id', 'sequence_id', 'sign', 'start_frame', 'end_frame', 'total_frames', \n",
    "    'face_nan_count', 'face_nan_pct', 'left_hand_nan_count', 'left_hand_nan_pct', 'pose_nan_count', 'pose_nan_pct',\n",
    "    'right_hand_nan_count', 'right_hand_nan_pct', 'x_min', 'x_max', 'y_min', 'y_max', 'z_min', 'z_max',\n",
    "]\n",
    "\n",
    "LOAD_EXTENDED = False\n",
    "if not LOAD_EXTENDED:\n",
    "    # Will take around 5-10 minutes on subsample and around 50-100 minutes on the full dataset\n",
    "    subsample_train_df = subsample_train_df.progress_apply(lambda x: get_seq_meta(x, do_counts=True), axis=1)\n",
    "    for _type, _count in type_kp_map.items():\n",
    "        subsample_train_df[f\"{_type}_appears_pct\"] = subsample_train_df[f\"{_type}_count\"]/(subsample_train_df[f\"total_frames\"]*_count)\n",
    "        subsample_train_df[f\"{_type}_nan_pct\"]     = subsample_train_df[f\"{_type}_nan_count\"]/(subsample_train_df[f\"total_frames\"]*_count)\n",
    "    # Extended save for later...\n",
    "    subsample_train_df.to_csv(\"extended_train.csv\", index=False)\n",
    "    display(subsample_train_df)\n",
    "else:\n",
    "    del subsample_train_df\n",
    "    for _type, _count in type_kp_map.items():\n",
    "            train_df[f\"{_type}_appears_pct\"] = train_df[f\"{_type}_count\"]/(train_df[f\"total_frames\"]*_count)\n",
    "            train_df[f\"{_type}_nan_pct\"]     = train_df[f\"{_type}_nan_count\"]/(train_df[f\"total_frames\"]*_count)\n",
    "    train_df = train_df[col_order]\n",
    "    display(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88519267",
   "metadata": {},
   "source": [
    "#### Sources:\n",
    "https://www.kaggle.com/code/dschettler8845/gislr-learn-eda-baseline\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,auto:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
