{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c5460ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t– MATPLOTLIB VERSION: 3.6.3\n",
      "Renderers configuration\n",
      "-----------------------\n",
      "    Default renderer: 'plotly_mimetype+notebook'\n",
      "    Available renderers:\n",
      "        ['plotly_mimetype', 'jupyterlab', 'nteract', 'vscode',\n",
      "         'notebook', 'notebook_connected', 'kaggle', 'azure', 'colab',\n",
      "         'cocalc', 'databricks', 'json', 'png', 'jpeg', 'jpg', 'svg',\n",
      "         'pdf', 'browser', 'firefox', 'chrome', 'chromium', 'iframe',\n",
      "         'iframe_connected', 'sphinx_gallery', 'sphinx_gallery_png']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Machine Learning and Data Science Imports\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from tqdm import tqdm\n",
    "\n",
    "# for running on CoLab or within Kaggle\n",
    "# from kaggle_datasets import KaggleDatasets\n",
    "\n",
    "# Mostly Builtins\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from zipfile import ZipFile\n",
    "from glob import glob\n",
    "import Levenshtein\n",
    "import warnings\n",
    "import requests\n",
    "import hashlib\n",
    "import imageio\n",
    "import IPython\n",
    "import sklearn\n",
    "import urllib\n",
    "import zipfile\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import string\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import gzip\n",
    "import ast\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "\n",
    "# Visualization Imports (overkill)\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.patches as patches\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm; tqdm.pandas();\n",
    "import plotly.express as px\n",
    "import tifffile as tif\n",
    "import seaborn as sns\n",
    "from PIL import Image, ImageEnhance; Image.MAX_IMAGE_PIXELS = 5_000_000_000;\n",
    "import matplotlib; print(f\"\\t\\t– MATPLOTLIB VERSION: {matplotlib.__version__}\");\n",
    "from matplotlib import animation, rc; rc('animation', html='jshtml')\n",
    "import plotly\n",
    "import PIL\n",
    "\n",
    "import plotly.io as pio\n",
    "print(pio.renderers)\n",
    "\n",
    "def seed_it_all(seed=7):\n",
    "    \"\"\" Attempt to be Reproducible \"\"\"\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "seed_it_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d4269d",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2e2f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_l_o_l(nested_list):\n",
    "    \"\"\"Flatten a list of lists into a single list.\n",
    "\n",
    "    Args:\n",
    "        nested_list (list): \n",
    "            – A list of lists (or iterables) to be flattened.\n",
    "\n",
    "    Returns:\n",
    "        list: A flattened list containing all items from the input list of lists.\n",
    "    \"\"\"\n",
    "    return [item for sublist in nested_list for item in sublist]\n",
    "\n",
    "\n",
    "def print_ln(symbol=\"-\", line_len=110, newline_before=False, newline_after=False):\n",
    "    \"\"\"Print a horizontal line of a specified length and symbol.\n",
    "\n",
    "    Args:\n",
    "        symbol (str, optional): \n",
    "            – The symbol to use for the horizontal line\n",
    "        line_len (int, optional): \n",
    "            – The length of the horizontal line in characters\n",
    "        newline_before (bool, optional): \n",
    "            – Whether to print a newline character before the line\n",
    "        newline_after (bool, optional): \n",
    "            – Whether to print a newline character after the line\n",
    "    \"\"\"\n",
    "    if newline_before: print();\n",
    "    print(symbol * line_len)\n",
    "    if newline_after: print();\n",
    "        \n",
    "        \n",
    "def read_json_file(file_path):\n",
    "    \"\"\"Read a JSON file and parse it into a Python object.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the JSON file to read.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary object representing the JSON data.\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If the specified file path does not exist.\n",
    "        ValueError: If the specified file path does not contain valid JSON data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open the file and load the JSON data into a Python object\n",
    "        with open(file_path, 'r') as file:\n",
    "            json_data = json.load(file)\n",
    "        return json_data\n",
    "    except FileNotFoundError:\n",
    "        # Raise an error if the file path does not exist\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    except ValueError:\n",
    "        # Raise an error if the file does not contain valid JSON data\n",
    "        raise ValueError(f\"Invalid JSON data in file: {file_path}\")\n",
    "        \n",
    "def get_sign_df(pq_path, invert_y=True):\n",
    "    sign_df = pd.read_parquet(pq_path)\n",
    "    \n",
    "    # y value is inverted (Thanks @danielpeshkov)\n",
    "    if invert_y: sign_df[\"y\"] *= -1 \n",
    "        \n",
    "    return sign_df\n",
    "\n",
    "\n",
    "ROWS_PER_FRAME = 543  # number of landmarks per frame\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc1dbdc",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f84e0341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>26734</td>\n",
       "      <td>1000035562</td>\n",
       "      <td>blow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>28656</td>\n",
       "      <td>1000106739</td>\n",
       "      <td>wait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>16069</td>\n",
       "      <td>100015657</td>\n",
       "      <td>cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>25571</td>\n",
       "      <td>1000210073</td>\n",
       "      <td>bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>62590</td>\n",
       "      <td>1000240708</td>\n",
       "      <td>owie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94472</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>53618</td>\n",
       "      <td>999786174</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94473</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>26734</td>\n",
       "      <td>999799849</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94474</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>25571</td>\n",
       "      <td>999833418</td>\n",
       "      <td>flower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94475</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>29302</td>\n",
       "      <td>999895257</td>\n",
       "      <td>room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94476</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>36257</td>\n",
       "      <td>999962374</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94477 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    path  participant_id  \\\n",
       "0      C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...           26734   \n",
       "1      C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...           28656   \n",
       "2      C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...           16069   \n",
       "3      C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...           25571   \n",
       "4      C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...           62590   \n",
       "...                                                  ...             ...   \n",
       "94472  C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...           53618   \n",
       "94473  C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...           26734   \n",
       "94474  C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...           25571   \n",
       "94475  C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...           29302   \n",
       "94476  C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...           36257   \n",
       "\n",
       "       sequence_id    sign  \n",
       "0       1000035562    blow  \n",
       "1       1000106739    wait  \n",
       "2        100015657   cloud  \n",
       "3       1000210073    bird  \n",
       "4       1000240708    owie  \n",
       "...            ...     ...  \n",
       "94472    999786174   white  \n",
       "94473    999799849    have  \n",
       "94474    999833418  flower  \n",
       "94475    999895257    room  \n",
       "94476    999962374   happy  \n",
       "\n",
       "[94477 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "... LOAD SIGN TO PREDICTION INDEX MAP FROM JSON FILE ...\n",
      "\n",
      "{'tv': 0, 'after': 1, 'airplane': 2, 'all': 3, 'alligator': 4, 'animal': 5, 'another': 6, 'any': 7, 'apple': 8, 'arm': 9, 'aunt': 10, 'awake': 11, 'backyard': 12, 'bad': 13, 'balloon': 14, 'bath': 15, 'because': 16, 'bed': 17, 'bedroom': 18, 'bee': 19, 'before': 20, 'beside': 21, 'better': 22, 'bird': 23, 'black': 24, 'blow': 25, 'blue': 26, 'boat': 27, 'book': 28, 'boy': 29, 'brother': 30, 'brown': 31, 'bug': 32, 'bye': 33, 'callonphone': 34, 'can': 35, 'car': 36, 'carrot': 37, 'cat': 38, 'cereal': 39, 'chair': 40, 'cheek': 41, 'child': 42, 'chin': 43, 'chocolate': 44, 'clean': 45, 'close': 46, 'closet': 47, 'cloud': 48, 'clown': 49, 'cow': 50, 'cowboy': 51, 'cry': 52, 'cut': 53, 'cute': 54, 'dad': 55, 'dance': 56, 'dirty': 57, 'dog': 58, 'doll': 59, 'donkey': 60, 'down': 61, 'drawer': 62, 'drink': 63, 'drop': 64, 'dry': 65, 'dryer': 66, 'duck': 67, 'ear': 68, 'elephant': 69, 'empty': 70, 'every': 71, 'eye': 72, 'face': 73, 'fall': 74, 'farm': 75, 'fast': 76, 'feet': 77, 'find': 78, 'fine': 79, 'finger': 80, 'finish': 81, 'fireman': 82, 'first': 83, 'fish': 84, 'flag': 85, 'flower': 86, 'food': 87, 'for': 88, 'frenchfries': 89, 'frog': 90, 'garbage': 91, 'gift': 92, 'giraffe': 93, 'girl': 94, 'give': 95, 'glasswindow': 96, 'go': 97, 'goose': 98, 'grandma': 99, 'grandpa': 100, 'grass': 101, 'green': 102, 'gum': 103, 'hair': 104, 'happy': 105, 'hat': 106, 'hate': 107, 'have': 108, 'haveto': 109, 'head': 110, 'hear': 111, 'helicopter': 112, 'hello': 113, 'hen': 114, 'hesheit': 115, 'hide': 116, 'high': 117, 'home': 118, 'horse': 119, 'hot': 120, 'hungry': 121, 'icecream': 122, 'if': 123, 'into': 124, 'jacket': 125, 'jeans': 126, 'jump': 127, 'kiss': 128, 'kitty': 129, 'lamp': 130, 'later': 131, 'like': 132, 'lion': 133, 'lips': 134, 'listen': 135, 'look': 136, 'loud': 137, 'mad': 138, 'make': 139, 'man': 140, 'many': 141, 'milk': 142, 'minemy': 143, 'mitten': 144, 'mom': 145, 'moon': 146, 'morning': 147, 'mouse': 148, 'mouth': 149, 'nap': 150, 'napkin': 151, 'night': 152, 'no': 153, 'noisy': 154, 'nose': 155, 'not': 156, 'now': 157, 'nuts': 158, 'old': 159, 'on': 160, 'open': 161, 'orange': 162, 'outside': 163, 'owie': 164, 'owl': 165, 'pajamas': 166, 'pen': 167, 'pencil': 168, 'penny': 169, 'person': 170, 'pig': 171, 'pizza': 172, 'please': 173, 'police': 174, 'pool': 175, 'potty': 176, 'pretend': 177, 'pretty': 178, 'puppy': 179, 'puzzle': 180, 'quiet': 181, 'radio': 182, 'rain': 183, 'read': 184, 'red': 185, 'refrigerator': 186, 'ride': 187, 'room': 188, 'sad': 189, 'same': 190, 'say': 191, 'scissors': 192, 'see': 193, 'shhh': 194, 'shirt': 195, 'shoe': 196, 'shower': 197, 'sick': 198, 'sleep': 199, 'sleepy': 200, 'smile': 201, 'snack': 202, 'snow': 203, 'stairs': 204, 'stay': 205, 'sticky': 206, 'store': 207, 'story': 208, 'stuck': 209, 'sun': 210, 'table': 211, 'talk': 212, 'taste': 213, 'thankyou': 214, 'that': 215, 'there': 216, 'think': 217, 'thirsty': 218, 'tiger': 219, 'time': 220, 'tomorrow': 221, 'tongue': 222, 'tooth': 223, 'toothbrush': 224, 'touch': 225, 'toy': 226, 'tree': 227, 'uncle': 228, 'underwear': 229, 'up': 230, 'vacuum': 231, 'wait': 232, 'wake': 233, 'water': 234, 'wet': 235, 'weus': 236, 'where': 237, 'white': 238, 'who': 239, 'why': 240, 'will': 241, 'wolf': 242, 'yellow': 243, 'yes': 244, 'yesterday': 245, 'yourself': 246, 'yucky': 247, 'zebra': 248, 'zipper': 249}\n",
      "\n",
      "\n",
      "... DEMO SIGN/EVENT DATAFRAME FOR ROW 283 - SIGN=face ...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame</th>\n",
       "      <th>row_id</th>\n",
       "      <th>type</th>\n",
       "      <th>landmark_index</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>23-face-0</td>\n",
       "      <td>face</td>\n",
       "      <td>0</td>\n",
       "      <td>0.381393</td>\n",
       "      <td>-0.377334</td>\n",
       "      <td>-0.045009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>23-face-1</td>\n",
       "      <td>face</td>\n",
       "      <td>1</td>\n",
       "      <td>0.387510</td>\n",
       "      <td>-0.333088</td>\n",
       "      <td>-0.060799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>23-face-2</td>\n",
       "      <td>face</td>\n",
       "      <td>2</td>\n",
       "      <td>0.384334</td>\n",
       "      <td>-0.349668</td>\n",
       "      <td>-0.037500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>23-face-3</td>\n",
       "      <td>face</td>\n",
       "      <td>3</td>\n",
       "      <td>0.377555</td>\n",
       "      <td>-0.302792</td>\n",
       "      <td>-0.038101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>23-face-4</td>\n",
       "      <td>face</td>\n",
       "      <td>4</td>\n",
       "      <td>0.388338</td>\n",
       "      <td>-0.322209</td>\n",
       "      <td>-0.062246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9226</th>\n",
       "      <td>39</td>\n",
       "      <td>39-right_hand-16</td>\n",
       "      <td>right_hand</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9227</th>\n",
       "      <td>39</td>\n",
       "      <td>39-right_hand-17</td>\n",
       "      <td>right_hand</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9228</th>\n",
       "      <td>39</td>\n",
       "      <td>39-right_hand-18</td>\n",
       "      <td>right_hand</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9229</th>\n",
       "      <td>39</td>\n",
       "      <td>39-right_hand-19</td>\n",
       "      <td>right_hand</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9230</th>\n",
       "      <td>39</td>\n",
       "      <td>39-right_hand-20</td>\n",
       "      <td>right_hand</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9231 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      frame            row_id        type  landmark_index         x         y  \\\n",
       "0        23         23-face-0        face               0  0.381393 -0.377334   \n",
       "1        23         23-face-1        face               1  0.387510 -0.333088   \n",
       "2        23         23-face-2        face               2  0.384334 -0.349668   \n",
       "3        23         23-face-3        face               3  0.377555 -0.302792   \n",
       "4        23         23-face-4        face               4  0.388338 -0.322209   \n",
       "...     ...               ...         ...             ...       ...       ...   \n",
       "9226     39  39-right_hand-16  right_hand              16       NaN       NaN   \n",
       "9227     39  39-right_hand-17  right_hand              17       NaN       NaN   \n",
       "9228     39  39-right_hand-18  right_hand              18       NaN       NaN   \n",
       "9229     39  39-right_hand-19  right_hand              19       NaN       NaN   \n",
       "9230     39  39-right_hand-20  right_hand              20       NaN       NaN   \n",
       "\n",
       "             z  \n",
       "0    -0.045009  \n",
       "1    -0.060799  \n",
       "2    -0.037500  \n",
       "3    -0.038101  \n",
       "4    -0.062246  \n",
       "...        ...  \n",
       "9226       NaN  \n",
       "9227       NaN  \n",
       "9228       NaN  \n",
       "9229       NaN  \n",
       "9230       NaN  \n",
       "\n",
       "[9231 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the path to the root data directory\n",
    "DATA_DIR         = str(os.getcwd()) + r\"\\asl-signs\"\n",
    "EXTEND_TRAIN_DIR = \"/asl-signs/gislr-extended-train-dataframe\" \n",
    "\n",
    "LOAD_EXTENDED = True\n",
    "if LOAD_EXTENDED and os.path.isfile(os.path.join(EXTEND_TRAIN_DIR, \"extended_train.csv\")):\n",
    "    train_df = pd.read_csv(os.path.join(EXTEND_TRAIN_DIR, \"extended_train.csv\"))\n",
    "else:\n",
    "    train_df = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"))\n",
    "    train_df[\"path\"] = DATA_DIR+\"\\\\\"+train_df[\"path\"]\n",
    "display(train_df)\n",
    "\n",
    "print(\"\\n\\n... LOAD SIGN TO PREDICTION INDEX MAP FROM JSON FILE ...\\n\")\n",
    "s2p_map = {k.lower():v for k,v in read_json_file(os.path.join(DATA_DIR, \"sign_to_prediction_index_map.json\")).items()}\n",
    "p2s_map = {v:k for k,v in read_json_file(os.path.join(DATA_DIR, \"sign_to_prediction_index_map.json\")).items()}\n",
    "encoder = lambda x: s2p_map.get(x.lower())\n",
    "decoder = lambda x: p2s_map.get(x)\n",
    "print(s2p_map)\n",
    "\n",
    "DEMO_ROW = 283\n",
    "print(f\"\\n\\n... DEMO SIGN/EVENT DATAFRAME FOR ROW {DEMO_ROW} - SIGN={train_df.iloc[DEMO_ROW]['sign']} ...\\n\")\n",
    "demo_sign_df = get_sign_df(train_df.iloc[DEMO_ROW][\"path\"])\n",
    "display(demo_sign_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873ded6b",
   "metadata": {},
   "source": [
    "### Sample Training Data\n",
    "#### There is a lot of data here (some ~50gb) so we're going to start with doing EDA on just some of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4ff7e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>28656</td>\n",
       "      <td>3311214787</td>\n",
       "      <td>sticky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>53618</td>\n",
       "      <td>3588192588</td>\n",
       "      <td>before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>4718</td>\n",
       "      <td>1363575346</td>\n",
       "      <td>pretty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>37779</td>\n",
       "      <td>951199059</td>\n",
       "      <td>hen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>36257</td>\n",
       "      <td>283190141</td>\n",
       "      <td>tomorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>22343</td>\n",
       "      <td>2499821466</td>\n",
       "      <td>pizza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>30680</td>\n",
       "      <td>2427202243</td>\n",
       "      <td>farm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>53618</td>\n",
       "      <td>532239954</td>\n",
       "      <td>outside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>4718</td>\n",
       "      <td>3232372656</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>4718</td>\n",
       "      <td>2745479422</td>\n",
       "      <td>finish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 path  participant_id  \\\n",
       "0   C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...           28656   \n",
       "1   C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...           53618   \n",
       "2   C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...            4718   \n",
       "3   C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...           37779   \n",
       "4   C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...           36257   \n",
       "..                                                ...             ...   \n",
       "89  C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...           22343   \n",
       "90  C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...           30680   \n",
       "91  C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...           53618   \n",
       "92  C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...            4718   \n",
       "93  C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...            4718   \n",
       "\n",
       "    sequence_id      sign  \n",
       "0    3311214787    sticky  \n",
       "1    3588192588    before  \n",
       "2    1363575346    pretty  \n",
       "3     951199059       hen  \n",
       "4     283190141  tomorrow  \n",
       "..          ...       ...  \n",
       "89   2499821466     pizza  \n",
       "90   2427202243      farm  \n",
       "91    532239954   outside  \n",
       "92   3232372656     water  \n",
       "93   2745479422    finish  \n",
       "\n",
       "[94 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# During interactive --> 0.001 (0.1%)\n",
    "# Save and run-all   --> 1.000 (100%)\n",
    "\n",
    "PCT_TO_EXAMINE = 0.001\n",
    "if PCT_TO_EXAMINE < 1.0:\n",
    "    subsample_train_df = train_df.sample(frac=PCT_TO_EXAMINE, random_state=42).reset_index(drop=True)\n",
    "else:\n",
    "    subsample_train_df = train_df.copy()\n",
    "\n",
    "# Remove extra columns to show what we're doing\n",
    "subsample_train_df=subsample_train_df[[\"path\", \"participant_id\", \"sequence_id\", \"sign\"]]\n",
    "display(subsample_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e01e59",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0ab96e",
   "metadata": {},
   "source": [
    "##### Data Dictionary (columns and their meanings)\n",
    "Path - filepath to the landmark file (parquet)\n",
    "participant_id - who the isolated sign event parquet files are for\n",
    "sequence_id - one sequence is a single isolated sign that we have to classify (one parquet file for each, 94,477)\n",
    "sign - the label for each event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdeb25e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <td>94477</td>\n",
       "      <td>21</td>\n",
       "      <td>49445</td>\n",
       "      <td>4968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count unique    top  freq\n",
       "participant_id  94477     21  49445  4968"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "1. Number of Unique Participants:  21\n",
      "2. Average Number of Rows Per Participant:  4498.9047619047615\n",
      "3. Standard Deviation in Counts Per Participant:  490.7731417304649\n",
      "4. Minimum Number of Examples For One Participant:  3338\n",
      "5. Maximum Number of Examples For One Participant:  4968\n"
     ]
    }
   ],
   "source": [
    "# Here we're looking at the participant_id column\n",
    "display(train_df[\"participant_id\"].astype(str).describe().to_frame().T)\n",
    "\n",
    "print('--------------------------------------------')\n",
    "\n",
    "participant_count_map = train_df[\"participant_id\"].value_counts().to_dict()\n",
    "print(\"1. Number of Unique Participants: \", len(participant_count_map))\n",
    "print(\"2. Average Number of Rows Per Participant: \", np.array(list(participant_count_map.values())).mean())\n",
    "print(\"3. Standard Deviation in Counts Per Participant: \", np.array(list(participant_count_map.values())).std())\n",
    "print(\"4. Minimum Number of Examples For One Participant: \", np.array(list(participant_count_map.values())).min())\n",
    "print(\"5. Maximum Number of Examples For One Participant: \", np.array(list(participant_count_map.values())).max())\n",
    "\n",
    "# set participant_id to be a string\n",
    "train_df[\"participant_id\"] = train_df[\"participant_id\"].astype(str)\n",
    "subsample_train_df[\"participant_id\"] = subsample_train_df[\"participant_id\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ded781d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sign</th>\n",
       "      <td>94477</td>\n",
       "      <td>250</td>\n",
       "      <td>listen</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count unique     top freq\n",
       "sign  94477    250  listen  415"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "1. Number Of Unique Signs:  250\n",
      "2. Average Number of Rows Per Sign:  377.908\n",
      "3. Standard Deviation in Counts Per Sign:  19.356537293638034\n",
      "4. Minimum Number of Examples For One Sign:  299\n",
      "5. Maximum Number of Examples For One Sign:  415\n"
     ]
    }
   ],
   "source": [
    "# Here we are looking at the 'sign' column\n",
    "display(train_df[\"sign\"].describe().to_frame().T)\n",
    "\n",
    "print('-----------------------------------------------')\n",
    "\n",
    "sign_count_map = train_df[\"sign\"].value_counts().to_dict()\n",
    "print(\"1. Number Of Unique Signs: \", len(sign_count_map))\n",
    "print(\"2. Average Number of Rows Per Sign: \", np.array(list(sign_count_map.values())).mean())\n",
    "print(\"3. Standard Deviation in Counts Per Sign: \", np.array(list(sign_count_map.values())).std())\n",
    "print(\"4. Minimum Number of Examples For One Sign: \", np.array(list(sign_count_map.values())).min())\n",
    "print(\"5. Maximum Number of Examples For One Sign: \", np.array(list(sign_count_map.values())).max())\n",
    "\n",
    "# Looks like the data is pretty balanced\n",
    "# i.e. one sign is not overly represented way more than the others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e594ad1",
   "metadata": {},
   "source": [
    "#### Now let's look at what data from the sequence parquet files might be important to include in our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c75843",
   "metadata": {},
   "source": [
    "For each sequence there is:\n",
    "1. start_frame\n",
    "2. end_frame\n",
    "3. total_frames\n",
    "4. face_count\n",
    "5. pose_count\n",
    "6. left_hand_count\n",
    "7. right_hand_count\n",
    "8. x_min\n",
    "9. x_max\n",
    "10. y_min\n",
    "11. y_max\n",
    "12. z_min\n",
    "13. z_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d7c175",
   "metadata": {},
   "source": [
    "### Data / Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b85eacdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2d41feb26744af8f306cbbd2ee04a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sign</th>\n",
       "      <th>start_frame</th>\n",
       "      <th>end_frame</th>\n",
       "      <th>total_frames</th>\n",
       "      <th>face_count</th>\n",
       "      <th>face_nan_count</th>\n",
       "      <th>pose_count</th>\n",
       "      <th>pose_nan_count</th>\n",
       "      <th>left_hand_count</th>\n",
       "      <th>left_hand_nan_count</th>\n",
       "      <th>right_hand_count</th>\n",
       "      <th>right_hand_nan_count</th>\n",
       "      <th>x_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_min</th>\n",
       "      <th>y_max</th>\n",
       "      <th>z_min</th>\n",
       "      <th>z_max</th>\n",
       "      <th>face_appears_pct</th>\n",
       "      <th>face_nan_pct</th>\n",
       "      <th>left_hand_appears_pct</th>\n",
       "      <th>left_hand_nan_pct</th>\n",
       "      <th>pose_appears_pct</th>\n",
       "      <th>pose_nan_pct</th>\n",
       "      <th>right_hand_appears_pct</th>\n",
       "      <th>right_hand_nan_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>28656</td>\n",
       "      <td>3311214787</td>\n",
       "      <td>sticky</td>\n",
       "      <td>22</td>\n",
       "      <td>42</td>\n",
       "      <td>21</td>\n",
       "      <td>9828</td>\n",
       "      <td>0</td>\n",
       "      <td>693</td>\n",
       "      <td>0</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.047753</td>\n",
       "      <td>1.208341</td>\n",
       "      <td>-2.479753</td>\n",
       "      <td>-0.272177</td>\n",
       "      <td>-2.455090</td>\n",
       "      <td>2.119155</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>53618</td>\n",
       "      <td>3588192588</td>\n",
       "      <td>before</td>\n",
       "      <td>12</td>\n",
       "      <td>112</td>\n",
       "      <td>101</td>\n",
       "      <td>47268</td>\n",
       "      <td>0</td>\n",
       "      <td>3333</td>\n",
       "      <td>0</td>\n",
       "      <td>2121</td>\n",
       "      <td>2121</td>\n",
       "      <td>2121</td>\n",
       "      <td>1449</td>\n",
       "      <td>-0.154611</td>\n",
       "      <td>1.127325</td>\n",
       "      <td>-2.669912</td>\n",
       "      <td>-0.180370</td>\n",
       "      <td>-3.773157</td>\n",
       "      <td>2.343476</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.683168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>4718</td>\n",
       "      <td>1363575346</td>\n",
       "      <td>pretty</td>\n",
       "      <td>1</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>59436</td>\n",
       "      <td>0</td>\n",
       "      <td>4191</td>\n",
       "      <td>0</td>\n",
       "      <td>2667</td>\n",
       "      <td>2667</td>\n",
       "      <td>2667</td>\n",
       "      <td>735</td>\n",
       "      <td>-0.051283</td>\n",
       "      <td>1.144013</td>\n",
       "      <td>-2.387898</td>\n",
       "      <td>-0.329061</td>\n",
       "      <td>-3.353845</td>\n",
       "      <td>2.562279</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.275591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>37779</td>\n",
       "      <td>951199059</td>\n",
       "      <td>hen</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>4212</td>\n",
       "      <td>0</td>\n",
       "      <td>297</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "      <td>0.070319</td>\n",
       "      <td>0.878191</td>\n",
       "      <td>-2.065159</td>\n",
       "      <td>-0.354841</td>\n",
       "      <td>-2.383077</td>\n",
       "      <td>1.343466</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>36257</td>\n",
       "      <td>283190141</td>\n",
       "      <td>tomorrow</td>\n",
       "      <td>59</td>\n",
       "      <td>109</td>\n",
       "      <td>51</td>\n",
       "      <td>23868</td>\n",
       "      <td>0</td>\n",
       "      <td>1683</td>\n",
       "      <td>0</td>\n",
       "      <td>1071</td>\n",
       "      <td>126</td>\n",
       "      <td>1071</td>\n",
       "      <td>1071</td>\n",
       "      <td>-0.225522</td>\n",
       "      <td>0.994753</td>\n",
       "      <td>-2.381426</td>\n",
       "      <td>-0.232735</td>\n",
       "      <td>-2.751159</td>\n",
       "      <td>1.393625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>22343</td>\n",
       "      <td>2499821466</td>\n",
       "      <td>pizza</td>\n",
       "      <td>27</td>\n",
       "      <td>47</td>\n",
       "      <td>21</td>\n",
       "      <td>9828</td>\n",
       "      <td>0</td>\n",
       "      <td>693</td>\n",
       "      <td>0</td>\n",
       "      <td>441</td>\n",
       "      <td>0</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>-0.320647</td>\n",
       "      <td>0.989240</td>\n",
       "      <td>-2.383032</td>\n",
       "      <td>-0.273714</td>\n",
       "      <td>-1.923812</td>\n",
       "      <td>1.336504</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>30680</td>\n",
       "      <td>2427202243</td>\n",
       "      <td>farm</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>5148</td>\n",
       "      <td>1872</td>\n",
       "      <td>363</td>\n",
       "      <td>0</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>147</td>\n",
       "      <td>-0.014882</td>\n",
       "      <td>1.423866</td>\n",
       "      <td>-2.372844</td>\n",
       "      <td>-0.286010</td>\n",
       "      <td>-2.641979</td>\n",
       "      <td>2.520685</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>53618</td>\n",
       "      <td>532239954</td>\n",
       "      <td>outside</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>3276</td>\n",
       "      <td>0</td>\n",
       "      <td>231</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>147</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.074550</td>\n",
       "      <td>1.205777</td>\n",
       "      <td>-2.470835</td>\n",
       "      <td>-0.292676</td>\n",
       "      <td>-3.225456</td>\n",
       "      <td>2.095151</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>4718</td>\n",
       "      <td>3232372656</td>\n",
       "      <td>water</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1404</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0.085591</td>\n",
       "      <td>0.964447</td>\n",
       "      <td>-2.091673</td>\n",
       "      <td>-0.334734</td>\n",
       "      <td>-2.128868</td>\n",
       "      <td>1.611341</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>4718</td>\n",
       "      <td>2745479422</td>\n",
       "      <td>finish</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>11700</td>\n",
       "      <td>0</td>\n",
       "      <td>825</td>\n",
       "      <td>0</td>\n",
       "      <td>525</td>\n",
       "      <td>525</td>\n",
       "      <td>525</td>\n",
       "      <td>420</td>\n",
       "      <td>-0.058602</td>\n",
       "      <td>0.901699</td>\n",
       "      <td>-2.233373</td>\n",
       "      <td>-0.300790</td>\n",
       "      <td>-2.532287</td>\n",
       "      <td>2.139560</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 path participant_id  \\\n",
       "0   C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...          28656   \n",
       "1   C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...          53618   \n",
       "2   C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...           4718   \n",
       "3   C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...          37779   \n",
       "4   C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...          36257   \n",
       "..                                                ...            ...   \n",
       "89  C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...          22343   \n",
       "90  C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...          30680   \n",
       "91  C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...          53618   \n",
       "92  C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...           4718   \n",
       "93  C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...           4718   \n",
       "\n",
       "    sequence_id      sign  start_frame  end_frame  total_frames  face_count  \\\n",
       "0    3311214787    sticky           22         42            21        9828   \n",
       "1    3588192588    before           12        112           101       47268   \n",
       "2    1363575346    pretty            1        127           127       59436   \n",
       "3     951199059       hen           18         26             9        4212   \n",
       "4     283190141  tomorrow           59        109            51       23868   \n",
       "..          ...       ...          ...        ...           ...         ...   \n",
       "89   2499821466     pizza           27         47            21        9828   \n",
       "90   2427202243      farm           20         30            11        5148   \n",
       "91    532239954   outside           21         27             7        3276   \n",
       "92   3232372656     water            0          2             3        1404   \n",
       "93   2745479422    finish            3         27            25       11700   \n",
       "\n",
       "    face_nan_count  pose_count  pose_nan_count  left_hand_count  \\\n",
       "0                0         693               0              441   \n",
       "1                0        3333               0             2121   \n",
       "2                0        4191               0             2667   \n",
       "3                0         297               0              189   \n",
       "4                0        1683               0             1071   \n",
       "..             ...         ...             ...              ...   \n",
       "89               0         693               0              441   \n",
       "90            1872         363               0              231   \n",
       "91               0         231               0              147   \n",
       "92               0          99               0               63   \n",
       "93               0         825               0              525   \n",
       "\n",
       "    left_hand_nan_count  right_hand_count  right_hand_nan_count     x_min  \\\n",
       "0                   441               441                     0 -0.047753   \n",
       "1                  2121              2121                  1449 -0.154611   \n",
       "2                  2667              2667                   735 -0.051283   \n",
       "3                   189               189                     0  0.070319   \n",
       "4                   126              1071                  1071 -0.225522   \n",
       "..                  ...               ...                   ...       ...   \n",
       "89                    0               441                   441 -0.320647   \n",
       "90                  231               231                   147 -0.014882   \n",
       "91                  147               147                     0 -0.074550   \n",
       "92                   63                63                     0  0.085591   \n",
       "93                  525               525                   420 -0.058602   \n",
       "\n",
       "       x_max     y_min     y_max     z_min     z_max  face_appears_pct  \\\n",
       "0   1.208341 -2.479753 -0.272177 -2.455090  2.119155               1.0   \n",
       "1   1.127325 -2.669912 -0.180370 -3.773157  2.343476               1.0   \n",
       "2   1.144013 -2.387898 -0.329061 -3.353845  2.562279               1.0   \n",
       "3   0.878191 -2.065159 -0.354841 -2.383077  1.343466               1.0   \n",
       "4   0.994753 -2.381426 -0.232735 -2.751159  1.393625               1.0   \n",
       "..       ...       ...       ...       ...       ...               ...   \n",
       "89  0.989240 -2.383032 -0.273714 -1.923812  1.336504               1.0   \n",
       "90  1.423866 -2.372844 -0.286010 -2.641979  2.520685               1.0   \n",
       "91  1.205777 -2.470835 -0.292676 -3.225456  2.095151               1.0   \n",
       "92  0.964447 -2.091673 -0.334734 -2.128868  1.611341               1.0   \n",
       "93  0.901699 -2.233373 -0.300790 -2.532287  2.139560               1.0   \n",
       "\n",
       "    face_nan_pct  left_hand_appears_pct  left_hand_nan_pct  pose_appears_pct  \\\n",
       "0       0.000000                    1.0           1.000000               1.0   \n",
       "1       0.000000                    1.0           1.000000               1.0   \n",
       "2       0.000000                    1.0           1.000000               1.0   \n",
       "3       0.000000                    1.0           1.000000               1.0   \n",
       "4       0.000000                    1.0           0.117647               1.0   \n",
       "..           ...                    ...                ...               ...   \n",
       "89      0.000000                    1.0           0.000000               1.0   \n",
       "90      0.363636                    1.0           1.000000               1.0   \n",
       "91      0.000000                    1.0           1.000000               1.0   \n",
       "92      0.000000                    1.0           1.000000               1.0   \n",
       "93      0.000000                    1.0           1.000000               1.0   \n",
       "\n",
       "    pose_nan_pct  right_hand_appears_pct  right_hand_nan_pct  \n",
       "0            0.0                     1.0            0.000000  \n",
       "1            0.0                     1.0            0.683168  \n",
       "2            0.0                     1.0            0.275591  \n",
       "3            0.0                     1.0            0.000000  \n",
       "4            0.0                     1.0            1.000000  \n",
       "..           ...                     ...                 ...  \n",
       "89           0.0                     1.0            1.000000  \n",
       "90           0.0                     1.0            0.636364  \n",
       "91           0.0                     1.0            0.000000  \n",
       "92           0.0                     1.0            0.000000  \n",
       "93           0.0                     1.0            0.800000  \n",
       "\n",
       "[94 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_seq_meta(row, invert_y=True, do_counts=False):\n",
    "    \"\"\"Calculates and adds metadata to the given row of sign language event data.\n",
    "    \n",
    "    Args:\n",
    "        row (pandas.core.series.Series): A row of sign language event data containing columns:\n",
    "            path: The file path to the Parquet file containing the landmark data for the event.\n",
    "        invert_y (bool, optional): Whether to invert the y-coordinate of each landmark. Defaults to True.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.core.series.Series: The input row with added metadata columns:\n",
    "            start_frame: The frame number of the first frame in the event.\n",
    "            end_frame: The frame number of the last frame in the event.\n",
    "            total_frames: The number of frames in the event.\n",
    "            face_count: The number of landmarks in the 'face' type. [optional]\n",
    "            pose_count: The number of landmarks in the 'pose' type. [optional]\n",
    "            left_hand_count: The number of landmarks in the 'left_hand' type. [optional]\n",
    "            right_hand_count: The number of landmarks in the 'right_hand' type. [optional]\n",
    "            x_min: The minimum x-coordinate value of any landmark in the event.\n",
    "            x_max: The maximum x-coordinate value of any landmark in the event.\n",
    "            y_min: The minimum y-coordinate value of any landmark in the event.\n",
    "            y_max: The maximum y-coordinate value of any landmark in the event.\n",
    "            z_min: The minimum z-coordinate value of any landmark in the event.\n",
    "            z_max: The maximum z-coordinate value of any landmark in the event.\n",
    "    \"\"\"\n",
    "    # Extract the sign language event data from the Parquet file at the given path\n",
    "    df = get_sign_df(row['path'], invert_y=invert_y)\n",
    "    \n",
    "    # Count the number of landmarks in each type\n",
    "    type_counts = df['type'].value_counts(dropna=False).to_dict()\n",
    "    nan_counts  = df.groupby(\"type\")[\"x\"].apply(lambda x: x.isna().sum())\n",
    "    \n",
    "    # Calculate metadata for the event and add it to the input row\n",
    "    row['start_frame'] = df['frame'].min()\n",
    "    row['end_frame'] = df['frame'].max()\n",
    "    row['total_frames'] = df['frame'].nunique()\n",
    "    \n",
    "    if do_counts:\n",
    "        for _type in [\"face\", \"pose\", \"left_hand\", \"right_hand\"]:\n",
    "            row[f'{_type}_count'] = type_counts[_type]\n",
    "            row[f'{_type}_nan_count'] = nan_counts[_type]\n",
    "        \n",
    "    for coord in ['x', 'y', 'z']:\n",
    "        row[f'{coord}_min'] = df[coord].min()\n",
    "        row[f'{coord}_max'] = df[coord].max()\n",
    "    \n",
    "    return row\n",
    "\n",
    "type_kp_map = dict(face=468, left_hand=21, pose=33, right_hand=21)\n",
    "col_order = [\n",
    "    'path', 'participant_id', 'sequence_id', 'sign', 'start_frame', 'end_frame', 'total_frames', \n",
    "    'face_nan_count', 'face_nan_pct', 'left_hand_nan_count', 'left_hand_nan_pct', 'pose_nan_count', 'pose_nan_pct',\n",
    "    'right_hand_nan_count', 'right_hand_nan_pct', 'x_min', 'x_max', 'y_min', 'y_max', 'z_min', 'z_max',\n",
    "]\n",
    "\n",
    "LOAD_EXTENDED = False\n",
    "if not LOAD_EXTENDED:\n",
    "    # Will take around 5-10 minutes on subsample and around 50-100 minutes on the full dataset\n",
    "    subsample_train_df = subsample_train_df.progress_apply(lambda x: get_seq_meta(x, do_counts=True), axis=1)\n",
    "    for _type, _count in type_kp_map.items():\n",
    "        subsample_train_df[f\"{_type}_appears_pct\"] = subsample_train_df[f\"{_type}_count\"]/(subsample_train_df[f\"total_frames\"]*_count)\n",
    "        subsample_train_df[f\"{_type}_nan_pct\"]     = subsample_train_df[f\"{_type}_nan_count\"]/(subsample_train_df[f\"total_frames\"]*_count)\n",
    "    # Extended save for later...\n",
    "    subsample_train_df.to_csv(\"extended_train.csv\", index=False)\n",
    "    display(subsample_train_df)\n",
    "else:\n",
    "    del subsample_train_df\n",
    "    for _type, _count in type_kp_map.items():\n",
    "            train_df[f\"{_type}_appears_pct\"] = train_df[f\"{_type}_count\"]/(train_df[f\"total_frames\"]*_count)\n",
    "            train_df[f\"{_type}_nan_pct\"]     = train_df[f\"{_type}_nan_count\"]/(train_df[f\"total_frames\"]*_count)\n",
    "    train_df = train_df[col_order]\n",
    "    display(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7113c573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>26734</td>\n",
       "      <td>1000035562</td>\n",
       "      <td>blow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>28656</td>\n",
       "      <td>1000106739</td>\n",
       "      <td>wait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>16069</td>\n",
       "      <td>100015657</td>\n",
       "      <td>cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>25571</td>\n",
       "      <td>1000210073</td>\n",
       "      <td>bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>62590</td>\n",
       "      <td>1000240708</td>\n",
       "      <td>owie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94472</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>53618</td>\n",
       "      <td>999786174</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94473</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>26734</td>\n",
       "      <td>999799849</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94474</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>25571</td>\n",
       "      <td>999833418</td>\n",
       "      <td>flower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94475</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>29302</td>\n",
       "      <td>999895257</td>\n",
       "      <td>room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94476</th>\n",
       "      <td>C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...</td>\n",
       "      <td>36257</td>\n",
       "      <td>999962374</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94477 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    path participant_id  \\\n",
       "0      C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...          26734   \n",
       "1      C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...          28656   \n",
       "2      C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...          16069   \n",
       "3      C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...          25571   \n",
       "4      C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...          62590   \n",
       "...                                                  ...            ...   \n",
       "94472  C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...          53618   \n",
       "94473  C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...          26734   \n",
       "94474  C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...          25571   \n",
       "94475  C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...          29302   \n",
       "94476  C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tr...          36257   \n",
       "\n",
       "       sequence_id    sign  \n",
       "0       1000035562    blow  \n",
       "1       1000106739    wait  \n",
       "2        100015657   cloud  \n",
       "3       1000210073    bird  \n",
       "4       1000240708    owie  \n",
       "...            ...     ...  \n",
       "94472    999786174   white  \n",
       "94473    999799849    have  \n",
       "94474    999833418  flower  \n",
       "94475    999895257    room  \n",
       "94476    999962374   happy  \n",
       "\n",
       "[94477 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17d1498",
   "metadata": {},
   "source": [
    "### Create TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3999743",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    data_path = r'C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\\\'\n",
    "    sequence_length = 12\n",
    "    rows_per_frame = 543 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9544e030",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROWS_PER_FRAME = 543  # number of landmarks per frame\n",
    "\n",
    "def load_relevant_data_subset_with_imputation(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    data.replace(np.nan, 0, inplace=True)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)\n",
    "\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)\n",
    "\n",
    "def read_dict(file_path):\n",
    "    path = os.path.expanduser(file_path)\n",
    "    with open(path, \"r\") as f:\n",
    "        dic = json.load(f)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3595e7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TV': 0, 'after': 1, 'airplane': 2, 'all': 3, 'alligator': 4, 'animal': 5, 'another': 6, 'any': 7, 'apple': 8, 'arm': 9, 'aunt': 10, 'awake': 11, 'backyard': 12, 'bad': 13, 'balloon': 14, 'bath': 15, 'because': 16, 'bed': 17, 'bedroom': 18, 'bee': 19, 'before': 20, 'beside': 21, 'better': 22, 'bird': 23, 'black': 24, 'blow': 25, 'blue': 26, 'boat': 27, 'book': 28, 'boy': 29, 'brother': 30, 'brown': 31, 'bug': 32, 'bye': 33, 'callonphone': 34, 'can': 35, 'car': 36, 'carrot': 37, 'cat': 38, 'cereal': 39, 'chair': 40, 'cheek': 41, 'child': 42, 'chin': 43, 'chocolate': 44, 'clean': 45, 'close': 46, 'closet': 47, 'cloud': 48, 'clown': 49, 'cow': 50, 'cowboy': 51, 'cry': 52, 'cut': 53, 'cute': 54, 'dad': 55, 'dance': 56, 'dirty': 57, 'dog': 58, 'doll': 59, 'donkey': 60, 'down': 61, 'drawer': 62, 'drink': 63, 'drop': 64, 'dry': 65, 'dryer': 66, 'duck': 67, 'ear': 68, 'elephant': 69, 'empty': 70, 'every': 71, 'eye': 72, 'face': 73, 'fall': 74, 'farm': 75, 'fast': 76, 'feet': 77, 'find': 78, 'fine': 79, 'finger': 80, 'finish': 81, 'fireman': 82, 'first': 83, 'fish': 84, 'flag': 85, 'flower': 86, 'food': 87, 'for': 88, 'frenchfries': 89, 'frog': 90, 'garbage': 91, 'gift': 92, 'giraffe': 93, 'girl': 94, 'give': 95, 'glasswindow': 96, 'go': 97, 'goose': 98, 'grandma': 99, 'grandpa': 100, 'grass': 101, 'green': 102, 'gum': 103, 'hair': 104, 'happy': 105, 'hat': 106, 'hate': 107, 'have': 108, 'haveto': 109, 'head': 110, 'hear': 111, 'helicopter': 112, 'hello': 113, 'hen': 114, 'hesheit': 115, 'hide': 116, 'high': 117, 'home': 118, 'horse': 119, 'hot': 120, 'hungry': 121, 'icecream': 122, 'if': 123, 'into': 124, 'jacket': 125, 'jeans': 126, 'jump': 127, 'kiss': 128, 'kitty': 129, 'lamp': 130, 'later': 131, 'like': 132, 'lion': 133, 'lips': 134, 'listen': 135, 'look': 136, 'loud': 137, 'mad': 138, 'make': 139, 'man': 140, 'many': 141, 'milk': 142, 'minemy': 143, 'mitten': 144, 'mom': 145, 'moon': 146, 'morning': 147, 'mouse': 148, 'mouth': 149, 'nap': 150, 'napkin': 151, 'night': 152, 'no': 153, 'noisy': 154, 'nose': 155, 'not': 156, 'now': 157, 'nuts': 158, 'old': 159, 'on': 160, 'open': 161, 'orange': 162, 'outside': 163, 'owie': 164, 'owl': 165, 'pajamas': 166, 'pen': 167, 'pencil': 168, 'penny': 169, 'person': 170, 'pig': 171, 'pizza': 172, 'please': 173, 'police': 174, 'pool': 175, 'potty': 176, 'pretend': 177, 'pretty': 178, 'puppy': 179, 'puzzle': 180, 'quiet': 181, 'radio': 182, 'rain': 183, 'read': 184, 'red': 185, 'refrigerator': 186, 'ride': 187, 'room': 188, 'sad': 189, 'same': 190, 'say': 191, 'scissors': 192, 'see': 193, 'shhh': 194, 'shirt': 195, 'shoe': 196, 'shower': 197, 'sick': 198, 'sleep': 199, 'sleepy': 200, 'smile': 201, 'snack': 202, 'snow': 203, 'stairs': 204, 'stay': 205, 'sticky': 206, 'store': 207, 'story': 208, 'stuck': 209, 'sun': 210, 'table': 211, 'talk': 212, 'taste': 213, 'thankyou': 214, 'that': 215, 'there': 216, 'think': 217, 'thirsty': 218, 'tiger': 219, 'time': 220, 'tomorrow': 221, 'tongue': 222, 'tooth': 223, 'toothbrush': 224, 'touch': 225, 'toy': 226, 'tree': 227, 'uncle': 228, 'underwear': 229, 'up': 230, 'vacuum': 231, 'wait': 232, 'wake': 233, 'water': 234, 'wet': 235, 'weus': 236, 'where': 237, 'white': 238, 'who': 239, 'why': 240, 'will': 241, 'wolf': 242, 'yellow': 243, 'yes': 244, 'yesterday': 245, 'yourself': 246, 'yucky': 247, 'zebra': 248, 'zipper': 249}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sign</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_landmark_files/26734/1000035562.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>1000035562</td>\n",
       "      <td>blow</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_landmark_files/28656/1000106739.parquet</td>\n",
       "      <td>28656</td>\n",
       "      <td>1000106739</td>\n",
       "      <td>wait</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_landmark_files/16069/100015657.parquet</td>\n",
       "      <td>16069</td>\n",
       "      <td>100015657</td>\n",
       "      <td>cloud</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_landmark_files/25571/1000210073.parquet</td>\n",
       "      <td>25571</td>\n",
       "      <td>1000210073</td>\n",
       "      <td>bird</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_landmark_files/62590/1000240708.parquet</td>\n",
       "      <td>62590</td>\n",
       "      <td>1000240708</td>\n",
       "      <td>owie</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            path  participant_id  sequence_id  \\\n",
       "0  train_landmark_files/26734/1000035562.parquet           26734   1000035562   \n",
       "1  train_landmark_files/28656/1000106739.parquet           28656   1000106739   \n",
       "2   train_landmark_files/16069/100015657.parquet           16069    100015657   \n",
       "3  train_landmark_files/25571/1000210073.parquet           25571   1000210073   \n",
       "4  train_landmark_files/62590/1000240708.parquet           62590   1000240708   \n",
       "\n",
       "    sign  label  \n",
       "0   blow     25  \n",
       "1   wait    232  \n",
       "2  cloud     48  \n",
       "3   bird     23  \n",
       "4   owie    164  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(r\"C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\train.csv\")\n",
    "label_index = read_dict(r\"C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\sign_to_prediction_index_map.json\")\n",
    "index_label = dict([(label_index[key], key) for key in label_index])\n",
    "print(label_index)\n",
    "train[\"label\"] = train[\"sign\"].map(lambda sign: label_index[sign])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8224afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_record(feature, label):\n",
    "    dic = {}\n",
    "    dic[\"feature\"] = tf.train.Feature(float_list=tf.train.FloatList(value=feature))\n",
    "    dic[\"label\"] = tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))\n",
    "    record_bytes = tf.train.Example(features=tf.train.Features(feature=dic)).SerializeToString()\n",
    "    return record_bytes\n",
    "    \n",
    "def decode_function(record_bytes):\n",
    "  return tf.io.parse_single_example(\n",
    "      # Data\n",
    "      record_bytes,\n",
    "      # Schema\n",
    "      {\n",
    "          \"feature\": tf.io.FixedLenFeature([CFG.sequence_length * CFG.rows_per_frame * 3], dtype=tf.float32),\n",
    "          \"label\": tf.io.FixedLenFeature([], dtype=tf.int64)\n",
    "      }\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3a3a492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tfrecords\\\\26734.tfrecords\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca28f84c7f24e659bf5bbc38cba1676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4841 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tfrecords\\\\28656.tfrecords\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af6475973c3248cdab3f4bc80d4cd71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tfrecords\\\\16069.tfrecords\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce1ce9f373ad43c4912428226178976e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4848 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tfrecords\\\\25571.tfrecords\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e036c1aac18e4f4ea75d30bfe4446e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3865 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tfrecords\\\\62590.tfrecords\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748f19bad7f0406985966d0e2fe21e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tfrecords\\\\32319.tfrecords\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3197c995df0141f68315b75a3569d3b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4753 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tfrecords\\\\37055.tfrecords\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f6b012c88a4bde83c9281ab8434173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4648 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tfrecords\\\\29302.tfrecords\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f20b566ead477e91621a3f6d79999c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4722 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tfrecords\\\\49445.tfrecords\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90aa6f6681dd4b5db2b1b6c4955de83c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4968 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tfrecords\\\\36257.tfrecords\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6d3c31ae8849a9bddd5d1085a56233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4896 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tfrecords\\\\22343.tfrecords\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba36b26a5184d89b6504f55c66ffc44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4677 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tfrecords\\\\27610.tfrecords\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a8ebaf7df51478b900bd1aadfa5fc5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tfrecords\\\\61333.tfrecords\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b80d07a86fce4c1897f5ccc8d26b6311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tfrecords\\\\53618.tfrecords\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c176d1eef6d84c20bc7726e6ca2baf8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4656 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tfrecords\\\\34503.tfrecords\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45bc5ec01a6420880597650b08002b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4545 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tfrecords\\\\18796.tfrecords\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11bac74e433c494096077110cb2d904a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tfrecords\\\\4718.tfrecords\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c7190784734bb6a98dd3b658e14a63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3499 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tfrecords\\\\55372.tfrecords\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d8f5db6eb4b4b889baf6cc8bdea14a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4826 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tfrecords\\\\2044.tfrecords\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b83c88de4b4abbb37b5e5416458515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4810 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tfrecords\\\\37779.tfrecords\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e60d8ea4924344ae20010f4a6f73e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\tfrecords\\\\30680.tfrecords\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3baa5aa8ed0848b5a66b3e2aa86e2f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3338 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cwd = os.getcwd() + r\"\\asl-signs\\tfrecords\\\\\"\n",
    "\n",
    "for participant_id in train.participant_id.unique():\n",
    "    df = train[train.participant_id == participant_id]\n",
    "    save_path = f\"{cwd}{participant_id}.tfrecords\"\n",
    "    print(save_path)\n",
    "    with tf.io.TFRecordWriter(save_path) as file_writer:\n",
    "        for i in tqdm(range(len(df))):\n",
    "            path = f\"{CFG.data_path}{df.iloc[i].path}\"\n",
    "            feature = load_relevant_data_subset_with_imputation(path)\n",
    "            feature = tf.image.resize(tf.constant(feature), (CFG.sequence_length, 543)).numpy().reshape(-1)\n",
    "            label = int(df.iloc[i].label)\n",
    "            file_writer.write(create_record(feature, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8ce042",
   "metadata": {},
   "source": [
    "### Baseline Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71aa6da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "train_x    = np.load(cwd + \"/asl-signs/gislr-feature-data/feature_data.npy\").astype(np.float32)\n",
    "train_y    = np.load(cwd + \"/asl-signs/gislr-feature-data/feature_labels.npy\").astype(np.uint8)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "N_TOTAL = train_x.shape[0]\n",
    "VAL_PCT = 0.1\n",
    "N_VAL   = int(N_TOTAL*VAL_PCT)\n",
    "N_TRAIN = N_TOTAL-N_VAL\n",
    "\n",
    "random_idxs = random.sample(range(N_TOTAL), N_TOTAL)\n",
    "train_idxs, val_idxs = np.array(random_idxs[:N_TRAIN]), np.array(random_idxs[N_TRAIN:])\n",
    "\n",
    "val_x, val_y = train_x[val_idxs], train_y[val_idxs]\n",
    "train_x, train_y = train_x[train_idxs], train_y[train_idxs]\n",
    "\n",
    "# train_ds = tf.data.Dataset.from_tensor_slices((train_x, train_y))\\\n",
    "#                           .shuffle(N_TRAIN)\\\n",
    "#                           .batch(BATCH_SIZE, drop_remainder=True)\\\n",
    "#                           .prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# val_ds = tf.data.Dataset.from_tensor_slices((train_x, train_y))\\\n",
    "#                           .shuffle(N_VAL)\\\n",
    "#                           .batch(BATCH_SIZE, drop_remainder=True)\\\n",
    "#                           .prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# train_ds, val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "820b08f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3258)]            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1668608   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 512)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 250)               64250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,867,258\n",
      "Trainable params: 1,865,722\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "def fc_block(inputs, output_channels, dropout=0.2):\n",
    "    x = tf.keras.layers.Dense(output_channels)(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"gelu\")(x)\n",
    "    x = tf.keras.layers.Dropout(dropout)(x)\n",
    "    return x\n",
    "\n",
    "def get_model(n_labels=250, init_fc=512, n_blocks=2, _dropout_1=0.2, _dropout_2=0.6, flat_frame_len=3258):\n",
    "    _inputs = tf.keras.layers.Input(shape=(flat_frame_len,))\n",
    "    x = _inputs\n",
    "    \n",
    "    # Define layers\n",
    "    for i in range(n_blocks):\n",
    "        x = fc_block(\n",
    "            x, output_channels=init_fc//(2**i), \n",
    "            dropout=_dropout_1 if (1+i)!=n_blocks else _dropout_2\n",
    "        )\n",
    "    \n",
    "    # Define output layer\n",
    "    _outputs = tf.keras.layers.Dense(n_labels, activation=\"softmax\")(x)\n",
    "    \n",
    "    # Build the model\n",
    "    model = tf.keras.models.Model(inputs=_inputs, outputs=_outputs)\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "model.compile(tf.keras.optimizers.Adam(0.000333), \"sparse_categorical_crossentropy\", metrics=\"acc\")\n",
    "model.summary()\n",
    "\n",
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147cb9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4ad5484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file models already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1329/1329 [==============================] - 24s 17ms/step - loss: 5.3707 - acc: 0.0146 - val_loss: 5.2390 - val_acc: 0.0187 - lr: 3.3300e-04\n",
      "Epoch 2/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 4.5584 - acc: 0.0637 - val_loss: 4.9709 - val_acc: 0.0281 - lr: 3.3300e-04\n",
      "Epoch 3/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 3.9586 - acc: 0.1287 - val_loss: 4.6137 - val_acc: 0.0626 - lr: 3.3300e-04\n",
      "Epoch 4/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 3.6219 - acc: 0.1743 - val_loss: 4.3904 - val_acc: 0.0923 - lr: 3.3300e-04\n",
      "Epoch 5/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 3.4130 - acc: 0.2144 - val_loss: 4.7804 - val_acc: 0.0555 - lr: 3.3300e-04\n",
      "Epoch 6/100\n",
      "1327/1329 [============================>.] - ETA: 0s - loss: 3.2548 - acc: 0.2428\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.000266400002874434.\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 3.2546 - acc: 0.2429 - val_loss: 4.8234 - val_acc: 0.0544 - lr: 3.3300e-04\n",
      "Epoch 7/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 3.0894 - acc: 0.2762 - val_loss: 3.8927 - val_acc: 0.1515 - lr: 2.6640e-04\n",
      "Epoch 8/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.9953 - acc: 0.2940 - val_loss: 3.7540 - val_acc: 0.1531 - lr: 2.6640e-04\n",
      "Epoch 9/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.9031 - acc: 0.3131 - val_loss: 4.1288 - val_acc: 0.1139 - lr: 2.6640e-04\n",
      "Epoch 10/100\n",
      "1328/1329 [============================>.] - ETA: 0s - loss: 2.8392 - acc: 0.3276\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00021311999298632145.\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.8393 - acc: 0.3276 - val_loss: 4.0527 - val_acc: 0.1170 - lr: 2.6640e-04\n",
      "Epoch 11/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.7375 - acc: 0.3480 - val_loss: 3.1008 - val_acc: 0.2718 - lr: 2.1312e-04\n",
      "Epoch 12/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.6821 - acc: 0.3603 - val_loss: 3.7976 - val_acc: 0.1599 - lr: 2.1312e-04\n",
      "Epoch 13/100\n",
      "1328/1329 [============================>.] - ETA: 0s - loss: 2.6373 - acc: 0.3698\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0001704959897324443.\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.6374 - acc: 0.3697 - val_loss: 3.3039 - val_acc: 0.2276 - lr: 2.1312e-04\n",
      "Epoch 14/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.5543 - acc: 0.3861 - val_loss: 2.9062 - val_acc: 0.3222 - lr: 1.7050e-04\n",
      "Epoch 15/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.5169 - acc: 0.3939 - val_loss: 3.1340 - val_acc: 0.2582 - lr: 1.7050e-04\n",
      "Epoch 16/100\n",
      "1329/1329 [==============================] - ETA: 0s - loss: 2.4897 - acc: 0.4006\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.000136396789457649.\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.4897 - acc: 0.4006 - val_loss: 3.6798 - val_acc: 0.1737 - lr: 1.7050e-04\n",
      "Epoch 17/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.4231 - acc: 0.4119 - val_loss: 2.7875 - val_acc: 0.3271 - lr: 1.3640e-04\n",
      "Epoch 18/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.3928 - acc: 0.4213 - val_loss: 2.6807 - val_acc: 0.3625 - lr: 1.3640e-04\n",
      "Epoch 19/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.3776 - acc: 0.4229 - val_loss: 2.8779 - val_acc: 0.3043 - lr: 1.3640e-04\n",
      "Epoch 20/100\n",
      "1328/1329 [============================>.] - ETA: 0s - loss: 2.3464 - acc: 0.4280\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0001091174315661192.\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.3464 - acc: 0.4280 - val_loss: 2.7920 - val_acc: 0.3229 - lr: 1.3640e-04\n",
      "Epoch 21/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.3021 - acc: 0.4391 - val_loss: 2.5913 - val_acc: 0.3737 - lr: 1.0912e-04\n",
      "Epoch 22/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.2833 - acc: 0.4455 - val_loss: 2.4172 - val_acc: 0.4190 - lr: 1.0912e-04\n",
      "Epoch 23/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.2674 - acc: 0.4471 - val_loss: 2.5462 - val_acc: 0.3753 - lr: 1.0912e-04\n",
      "Epoch 24/100\n",
      "1329/1329 [==============================] - ETA: 0s - loss: 2.2549 - acc: 0.4473\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 8.72939475812018e-05.\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.2549 - acc: 0.4473 - val_loss: 2.6815 - val_acc: 0.3474 - lr: 1.0912e-04\n",
      "Epoch 25/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.2194 - acc: 0.4551 - val_loss: 2.4761 - val_acc: 0.3881 - lr: 8.7294e-05\n",
      "Epoch 26/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.1974 - acc: 0.4598 - val_loss: 2.4068 - val_acc: 0.4099 - lr: 8.7294e-05\n",
      "Epoch 27/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.1857 - acc: 0.4631 - val_loss: 2.2120 - val_acc: 0.4684 - lr: 8.7294e-05\n",
      "Epoch 28/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.1733 - acc: 0.4640 - val_loss: 2.1585 - val_acc: 0.4726 - lr: 8.7294e-05\n",
      "Epoch 29/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.1629 - acc: 0.4679 - val_loss: 2.6132 - val_acc: 0.3873 - lr: 8.7294e-05\n",
      "Epoch 30/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.1512 - acc: 0.4704 - val_loss: 2.1137 - val_acc: 0.4879 - lr: 8.7294e-05\n",
      "Epoch 31/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.1363 - acc: 0.4740 - val_loss: 2.1989 - val_acc: 0.4537 - lr: 8.7294e-05\n",
      "Epoch 32/100\n",
      "1328/1329 [============================>.] - ETA: 0s - loss: 2.1249 - acc: 0.4754\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 6.983515922911466e-05.\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.1249 - acc: 0.4754 - val_loss: 2.2660 - val_acc: 0.4360 - lr: 8.7294e-05\n",
      "Epoch 33/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.1000 - acc: 0.4811 - val_loss: 2.1017 - val_acc: 0.4872 - lr: 6.9835e-05\n",
      "Epoch 34/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.0907 - acc: 0.4848 - val_loss: 2.0767 - val_acc: 0.4913 - lr: 6.9835e-05\n",
      "Epoch 35/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.0818 - acc: 0.4851 - val_loss: 2.1058 - val_acc: 0.4853 - lr: 6.9835e-05\n",
      "Epoch 36/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.0679 - acc: 0.4865 - val_loss: 2.0481 - val_acc: 0.5092 - lr: 6.9835e-05\n",
      "Epoch 37/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.0662 - acc: 0.4865 - val_loss: 2.3062 - val_acc: 0.4309 - lr: 6.9835e-05\n",
      "Epoch 38/100\n",
      "1327/1329 [============================>.] - ETA: 0s - loss: 2.0505 - acc: 0.4892\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 5.586812621913851e-05.\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.0507 - acc: 0.4892 - val_loss: 2.0753 - val_acc: 0.4933 - lr: 6.9835e-05\n",
      "Epoch 39/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.0350 - acc: 0.4946 - val_loss: 1.9804 - val_acc: 0.5118 - lr: 5.5868e-05\n",
      "Epoch 40/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.0218 - acc: 0.4968 - val_loss: 1.9397 - val_acc: 0.5279 - lr: 5.5868e-05\n",
      "Epoch 41/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.0181 - acc: 0.4996 - val_loss: 1.9013 - val_acc: 0.5374 - lr: 5.5868e-05\n",
      "Epoch 42/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.0097 - acc: 0.4982 - val_loss: 1.9778 - val_acc: 0.5178 - lr: 5.5868e-05\n",
      "Epoch 43/100\n",
      "1329/1329 [==============================] - ETA: 0s - loss: 2.0090 - acc: 0.5012\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 4.4694502139464025e-05.\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 2.0090 - acc: 0.5012 - val_loss: 1.9807 - val_acc: 0.5188 - lr: 5.5868e-05\n",
      "Epoch 44/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.9859 - acc: 0.5055 - val_loss: 1.8864 - val_acc: 0.5345 - lr: 4.4695e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.9802 - acc: 0.5081 - val_loss: 1.8467 - val_acc: 0.5500 - lr: 4.4695e-05\n",
      "Epoch 46/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.9677 - acc: 0.5102 - val_loss: 1.8369 - val_acc: 0.5537 - lr: 4.4695e-05\n",
      "Epoch 47/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.9693 - acc: 0.5081 - val_loss: 1.9087 - val_acc: 0.5346 - lr: 4.4695e-05\n",
      "Epoch 48/100\n",
      "1329/1329 [==============================] - ETA: 0s - loss: 1.9663 - acc: 0.5100\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 3.575560112949461e-05.\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.9663 - acc: 0.5100 - val_loss: 2.0163 - val_acc: 0.4950 - lr: 4.4695e-05\n",
      "Epoch 49/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.9472 - acc: 0.5140 - val_loss: 1.7719 - val_acc: 0.5702 - lr: 3.5756e-05\n",
      "Epoch 50/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.9473 - acc: 0.5135 - val_loss: 1.7787 - val_acc: 0.5682 - lr: 3.5756e-05\n",
      "Epoch 51/100\n",
      "1326/1329 [============================>.] - ETA: 0s - loss: 1.9445 - acc: 0.5138\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 2.8604481485672295e-05.\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.9443 - acc: 0.5138 - val_loss: 1.8063 - val_acc: 0.5602 - lr: 3.5756e-05\n",
      "Epoch 52/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.9301 - acc: 0.5176 - val_loss: 1.7381 - val_acc: 0.5791 - lr: 2.8604e-05\n",
      "Epoch 53/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.9202 - acc: 0.5208 - val_loss: 1.7225 - val_acc: 0.5824 - lr: 2.8604e-05\n",
      "Epoch 54/100\n",
      "1329/1329 [==============================] - 22s 17ms/step - loss: 1.9193 - acc: 0.5205 - val_loss: 1.7278 - val_acc: 0.5788 - lr: 2.8604e-05\n",
      "Epoch 55/100\n",
      "1327/1329 [============================>.] - ETA: 0s - loss: 1.9139 - acc: 0.5221\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 2.2883585188537836e-05.\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.9136 - acc: 0.5222 - val_loss: 1.7331 - val_acc: 0.5799 - lr: 2.8604e-05\n",
      "Epoch 56/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.9078 - acc: 0.5215 - val_loss: 1.7056 - val_acc: 0.5884 - lr: 2.2884e-05\n",
      "Epoch 57/100\n",
      "1329/1329 [==============================] - 22s 17ms/step - loss: 1.8941 - acc: 0.5243 - val_loss: 1.6826 - val_acc: 0.5916 - lr: 2.2884e-05\n",
      "Epoch 58/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.9031 - acc: 0.5235 - val_loss: 1.6886 - val_acc: 0.5870 - lr: 2.2884e-05\n",
      "Epoch 59/100\n",
      "1327/1329 [============================>.] - ETA: 0s - loss: 1.9021 - acc: 0.5264\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 1.830686815083027e-05.\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.9024 - acc: 0.5264 - val_loss: 1.7187 - val_acc: 0.5774 - lr: 2.2884e-05\n",
      "Epoch 60/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.8878 - acc: 0.5248 - val_loss: 1.7108 - val_acc: 0.5869 - lr: 1.8307e-05\n",
      "Epoch 61/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.8902 - acc: 0.5272 - val_loss: 1.6743 - val_acc: 0.5953 - lr: 1.8307e-05\n",
      "Epoch 62/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.8856 - acc: 0.5272 - val_loss: 1.6394 - val_acc: 0.6007 - lr: 1.8307e-05\n",
      "Epoch 63/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.8849 - acc: 0.5285 - val_loss: 1.6716 - val_acc: 0.5943 - lr: 1.8307e-05\n",
      "Epoch 64/100\n",
      "1326/1329 [============================>.] - ETA: 0s - loss: 1.8808 - acc: 0.5283\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 1.4645494229625912e-05.\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.8809 - acc: 0.5283 - val_loss: 1.6742 - val_acc: 0.6004 - lr: 1.8307e-05\n",
      "Epoch 65/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.8711 - acc: 0.5289 - val_loss: 1.6454 - val_acc: 0.6048 - lr: 1.4645e-05\n",
      "Epoch 66/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.8741 - acc: 0.5292 - val_loss: 1.6305 - val_acc: 0.6050 - lr: 1.4645e-05\n",
      "Epoch 67/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.8669 - acc: 0.5327 - val_loss: 1.6495 - val_acc: 0.5979 - lr: 1.4645e-05\n",
      "Epoch 68/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.8679 - acc: 0.5312 - val_loss: 1.6258 - val_acc: 0.6056 - lr: 1.4645e-05\n",
      "Epoch 69/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.8663 - acc: 0.5313 - val_loss: 1.6361 - val_acc: 0.6053 - lr: 1.4645e-05\n",
      "Epoch 70/100\n",
      "1326/1329 [============================>.] - ETA: 0s - loss: 1.8644 - acc: 0.5325\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 1.1716395238181577e-05.\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.8644 - acc: 0.5325 - val_loss: 1.6449 - val_acc: 0.5993 - lr: 1.4645e-05\n",
      "Epoch 71/100\n",
      "1329/1329 [==============================] - 22s 17ms/step - loss: 1.8552 - acc: 0.5327 - val_loss: 1.6026 - val_acc: 0.6133 - lr: 1.1716e-05\n",
      "Epoch 72/100\n",
      "1329/1329 [==============================] - 22s 17ms/step - loss: 1.8589 - acc: 0.5317 - val_loss: 1.6095 - val_acc: 0.6116 - lr: 1.1716e-05\n",
      "Epoch 73/100\n",
      "1328/1329 [============================>.] - ETA: 0s - loss: 1.8550 - acc: 0.5339\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 9.373116336064414e-06.\n",
      "1329/1329 [==============================] - 22s 17ms/step - loss: 1.8550 - acc: 0.5339 - val_loss: 1.6155 - val_acc: 0.6114 - lr: 1.1716e-05\n",
      "Epoch 74/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.8457 - acc: 0.5359 - val_loss: 1.6127 - val_acc: 0.6096 - lr: 9.3731e-06\n",
      "Epoch 75/100\n",
      "1329/1329 [==============================] - 22s 17ms/step - loss: 1.8450 - acc: 0.5342 - val_loss: 1.5985 - val_acc: 0.6102 - lr: 9.3731e-06\n",
      "Epoch 76/100\n",
      "1329/1329 [==============================] - 22s 17ms/step - loss: 1.8454 - acc: 0.5382 - val_loss: 1.5911 - val_acc: 0.6134 - lr: 9.3731e-06\n",
      "Epoch 77/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.8501 - acc: 0.5357 - val_loss: 1.5932 - val_acc: 0.6176 - lr: 9.3731e-06\n",
      "Epoch 78/100\n",
      "1326/1329 [============================>.] - ETA: 0s - loss: 1.8479 - acc: 0.5355\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 7.498492777813226e-06.\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.8475 - acc: 0.5355 - val_loss: 1.5958 - val_acc: 0.6155 - lr: 9.3731e-06\n",
      "Epoch 79/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.8454 - acc: 0.5353 - val_loss: 1.5942 - val_acc: 0.6156 - lr: 7.4985e-06\n",
      "Epoch 80/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.8442 - acc: 0.5368 - val_loss: 1.5839 - val_acc: 0.6155 - lr: 7.4985e-06\n",
      "Epoch 81/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.8387 - acc: 0.5347 - val_loss: 1.5875 - val_acc: 0.6138 - lr: 7.4985e-06\n",
      "Epoch 82/100\n",
      "1328/1329 [============================>.] - ETA: 0s - loss: 1.8395 - acc: 0.5353\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 5.998794222250581e-06.\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.8395 - acc: 0.5353 - val_loss: 1.5915 - val_acc: 0.6142 - lr: 7.4985e-06\n",
      "Epoch 83/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.8314 - acc: 0.5374 - val_loss: 1.5723 - val_acc: 0.6194 - lr: 5.9988e-06\n",
      "Epoch 84/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.8374 - acc: 0.5378 - val_loss: 1.5880 - val_acc: 0.6161 - lr: 5.9988e-06\n",
      "Epoch 85/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.8375 - acc: 0.5369 - val_loss: 1.5700 - val_acc: 0.6205 - lr: 5.9988e-06\n",
      "Epoch 86/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.8314 - acc: 0.5421 - val_loss: 1.5885 - val_acc: 0.6163 - lr: 5.9988e-06\n",
      "Epoch 87/100\n",
      "1327/1329 [============================>.] - ETA: 0s - loss: 1.8315 - acc: 0.5365\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 4.799035377800465e-06.\n",
      "1329/1329 [==============================] - 24s 18ms/step - loss: 1.8317 - acc: 0.5364 - val_loss: 1.5818 - val_acc: 0.6180 - lr: 5.9988e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "1329/1329 [==============================] - 23s 18ms/step - loss: 1.8313 - acc: 0.5404 - val_loss: 1.5686 - val_acc: 0.6219 - lr: 4.7990e-06\n",
      "Epoch 89/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.8220 - acc: 0.5394 - val_loss: 1.5702 - val_acc: 0.6190 - lr: 4.7990e-06\n",
      "Epoch 90/100\n",
      "1329/1329 [==============================] - 23s 18ms/step - loss: 1.8341 - acc: 0.5404 - val_loss: 1.5645 - val_acc: 0.6220 - lr: 4.7990e-06\n",
      "Epoch 91/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.8266 - acc: 0.5377 - val_loss: 1.5745 - val_acc: 0.6209 - lr: 4.7990e-06\n",
      "Epoch 92/100\n",
      "1326/1329 [============================>.] - ETA: 0s - loss: 1.8289 - acc: 0.5382\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 3.839228156721219e-06.\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.8291 - acc: 0.5381 - val_loss: 1.5672 - val_acc: 0.6202 - lr: 4.7990e-06\n",
      "Epoch 93/100\n",
      "1329/1329 [==============================] - 22s 17ms/step - loss: 1.8245 - acc: 0.5422 - val_loss: 1.5669 - val_acc: 0.6183 - lr: 3.8392e-06\n",
      "Epoch 94/100\n",
      "1329/1329 [==============================] - 22s 17ms/step - loss: 1.8235 - acc: 0.5407 - val_loss: 1.5629 - val_acc: 0.6225 - lr: 3.8392e-06\n",
      "Epoch 95/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.8240 - acc: 0.5396 - val_loss: 1.5640 - val_acc: 0.6221 - lr: 3.8392e-06\n",
      "Epoch 96/100\n",
      "1326/1329 [============================>.] - ETA: 0s - loss: 1.8231 - acc: 0.5407\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 3.071382525376976e-06.\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.8229 - acc: 0.5407 - val_loss: 1.5654 - val_acc: 0.6208 - lr: 3.8392e-06\n",
      "Epoch 97/100\n",
      "1329/1329 [==============================] - 22s 17ms/step - loss: 1.8279 - acc: 0.5395 - val_loss: 1.5662 - val_acc: 0.6226 - lr: 3.0714e-06\n",
      "Epoch 98/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.8262 - acc: 0.5403 - val_loss: 1.5567 - val_acc: 0.6251 - lr: 3.0714e-06\n",
      "Epoch 99/100\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.8150 - acc: 0.5425 - val_loss: 1.5633 - val_acc: 0.6213 - lr: 3.0714e-06\n",
      "Epoch 100/100\n",
      "1328/1329 [============================>.] - ETA: 0s - loss: 1.8222 - acc: 0.5396\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 2.4571059839217924e-06.\n",
      "1329/1329 [==============================] - 23s 17ms/step - loss: 1.8223 - acc: 0.5395 - val_loss: 1.5653 - val_acc: 0.6219 - lr: 3.0714e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/asl_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/asl_model\\assets\n"
     ]
    }
   ],
   "source": [
    "cb_list = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True, verbose=1),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(patience=2, factor=0.8, verbose=1)\n",
    "]\n",
    "history = model.fit(train_x, train_y, validation_data=(val_x, val_y), epochs=100, callbacks=cb_list, batch_size=BATCH_SIZE)\n",
    "model.save(\"./models/asl_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9beeaa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296/296 [==============================] - 1s 3ms/step - loss: 1.5653 - acc: 0.6219\n",
      "PRED: all                  – GT: all\n",
      "PRED: better               – GT: better\n",
      "PRED: kiss                 – GT: bug\n",
      "PRED: for                  – GT: horse\n",
      "PRED: animal               – GT: animal\n",
      "PRED: ear                  – GT: ear\n",
      "PRED: airplane             – GT: airplane\n",
      "PRED: time                 – GT: arm\n",
      "PRED: animal               – GT: beside\n",
      "PRED: pretend              – GT: pretend\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(val_x, val_y)\n",
    "for x,y in zip(val_x[:10], val_y[:10]):\n",
    "    print(f\"PRED: {decoder(np.argmax(model.predict(tf.expand_dims(x, axis=0), verbose=0), axis=-1)[0]):<20} – GT: {decoder(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69fce6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3258), dtype=float32, numpy=\n",
       "array([[ 0.52765715,  0.37799075, -0.03728105, ...,  0.15039368,\n",
       "         0.0695638 ,  0.04059875]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PrepInputs(tf.keras.layers.Layer):\n",
    "    def __init__(self, face_idx_range=(0, 468), lh_idx_range=(468, 489), \n",
    "                 pose_idx_range=(489, 522), rh_idx_range=(522, 543)):\n",
    "        super(PrepInputs, self).__init__()\n",
    "        self.idx_ranges = [face_idx_range, lh_idx_range, pose_idx_range, rh_idx_range]\n",
    "        self.flat_feat_lens = [3*(_range[1]-_range[0]) for _range in self.idx_ranges]\n",
    "    \n",
    "    def call(self, x_in):\n",
    "        \n",
    "        # Split the single vector into 4\n",
    "        xs = [x_in[:, _range[0]:_range[1], :] for _range in self.idx_ranges]\n",
    "        \n",
    "        # Reshape based on specific number of keypoints\n",
    "        xs = [tf.reshape(_x, (-1, flat_feat_len)) for _x, flat_feat_len in zip(xs, self.flat_feat_lens)]\n",
    "        \n",
    "        # Drop empty rows - Empty rows are present in \n",
    "        #   --> pose, lh, rh\n",
    "        #   --> so we don't have to for face\n",
    "        xs[1:] = [\n",
    "            tf.boolean_mask(_x, tf.reduce_all(tf.logical_not(tf.math.is_nan(_x)), axis=1), axis=0)\n",
    "            for _x in xs[1:]\n",
    "        ]\n",
    "        \n",
    "        # Get means and stds\n",
    "        x_means = [tf.math.reduce_mean(_x, axis=0) for _x in xs]\n",
    "        x_stds  = [tf.math.reduce_std(_x,  axis=0) for _x in xs]\n",
    "        \n",
    "        x_out = tf.concat([*x_means, *x_stds], axis=0)\n",
    "        x_out = tf.where(tf.math.is_finite(x_out), x_out, tf.zeros_like(x_out))\n",
    "        return tf.expand_dims(x_out, axis=0)\n",
    "    \n",
    "PrepInputs()(load_relevant_data_subset(train_df.path[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1637e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\repo\\math4920\\ASLKaggleProject\\asl-signs\\train_landmark_files/26734/1000035562.parquet\n"
     ]
    }
   ],
   "source": [
    "print(train_df.path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12079c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blow'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class TFLiteModel(tf.Module):\n",
    "    \"\"\"\n",
    "    TensorFlow Lite model that takes input tensors and applies:\n",
    "        – a preprocessing model\n",
    "        – the ISLR model \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, islr_model):\n",
    "        \"\"\"\n",
    "        Initializes the TFLiteModel with the specified preprocessing model and ISLR model.\n",
    "        \"\"\"\n",
    "        super(TFLiteModel, self).__init__()\n",
    "\n",
    "        # Load the feature generation and main models\n",
    "        self.prep_inputs = PrepInputs()\n",
    "        self.islr_model   = islr_model\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, 543, 3], dtype=tf.float32, name='inputs')])\n",
    "    def __call__(self, inputs):\n",
    "        \"\"\"\n",
    "        Applies the feature generation model and main model to the input tensors.\n",
    "\n",
    "        Args:\n",
    "            inputs: Input tensor with shape [batch_size, 543, 3].\n",
    "\n",
    "        Returns:\n",
    "            A dictionary with a single key 'outputs' and corresponding output tensor.\n",
    "        \"\"\"\n",
    "        x = self.prep_inputs(tf.cast(inputs, dtype=tf.float32))\n",
    "        outputs = self.islr_model(x)[0, :]\n",
    "\n",
    "        # Return a dictionary with the output tensor\n",
    "        return {'outputs': outputs}\n",
    "\n",
    "tflite_keras_model = TFLiteModel(islr_model=model)\n",
    "demo_output = tflite_keras_model(load_relevant_data_subset(train_df.path[0]))[\"outputs\"]\n",
    "decoder(np.argmax(demo_output.numpy(), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc255025",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall tflite_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14c3757",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tflite_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "66fba439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as prep_inputs_1_layer_call_fn, prep_inputs_1_layer_call_and_return_conditional_losses, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\T\\AppData\\Local\\Temp\\tmpg0u8tajt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\T\\AppData\\Local\\Temp\\tmpg0u8tajt\\assets\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "generic_type: type \"InterpreterWrapper\" is already registered!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(tflite_model)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# !zip submission.zip /kaggle/working/models/model.tflite\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtflite_runtime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterpreter\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtflite\u001b[39;00m\n\u001b[0;32m     10\u001b[0m interpreter \u001b[38;5;241m=\u001b[39m tflite\u001b[38;5;241m.\u001b[39mInterpreter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/working/models/model.tflite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m found_signatures \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(interpreter\u001b[38;5;241m.\u001b[39mget_signature_list()\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[1;32mc:\\repo\\math4920\\env\\lib\\site-packages\\tflite_runtime\\interpreter.py:41\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics_nonportable \u001b[38;5;28;01mas\u001b[39;00m metrics\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m   \u001b[38;5;66;03m# This file is part of tflite_runtime package.\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtflite_runtime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_tensorflow_interpreter_wrapper \u001b[38;5;28;01mas\u001b[39;00m _interpreter_wrapper\n\u001b[0;32m     42\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtflite_runtime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics_portable \u001b[38;5;28;01mas\u001b[39;00m metrics\n\u001b[0;32m     44\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_tf_export\u001b[39m(\u001b[38;5;241m*\u001b[39mx, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "\u001b[1;31mImportError\u001b[0m: generic_type: type \"InterpreterWrapper\" is already registered!"
     ]
    }
   ],
   "source": [
    "keras_model_converter = tf.lite.TFLiteConverter.from_keras_model(tflite_keras_model)\n",
    "tflite_model = keras_model_converter.convert()\n",
    "with open(r'C:\\repo\\math4920\\ASLKaggleProject\\kaggle\\working\\models\\model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "# !zip submission.zip /kaggle/working/models/model.tflite\n",
    "\n",
    "\n",
    "import tflite_runtime.interpreter as tflite\n",
    "\n",
    "interpreter = tflite.Interpreter(\"/kaggle/working/models/model.tflite\")\n",
    "found_signatures = list(interpreter.get_signature_list().keys())\n",
    "# if REQUIRED_SIGNATURE not in found_signatures:\n",
    "#     raise KernelEvalException('Required input signature not found.')\n",
    "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
    "\n",
    "output = prediction_fn(inputs=load_relevant_data_subset(train_df.path[0]))\n",
    "sign = np.argmax(output[\"outputs\"])\n",
    "\n",
    "print(\"PRED : \", decoder(sign))\n",
    "print(\"GT   : \", train_df.sign[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5553465c",
   "metadata": {},
   "source": [
    "#### Sources:\n",
    "https://www.kaggle.com/code/dschettler8845/gislr-learn-eda-baseline\n",
    "\n",
    "https://www.kaggle.com/code/lonnieqin/islr-create-tfrecord"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
